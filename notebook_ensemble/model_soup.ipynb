{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gab-palmeri/aml-geolocalization/blob/sam/step_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "n18u6OFZxF_z"
      },
      "source": [
        "The purpose of this notebook is evaluate individual models and try to do model soup technique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf3z5SqWZ91b"
      },
      "source": [
        "# pip install requirements\n",
        "\n",
        "Remember to click on \"Restart Runtime\" before go on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YbtEmI1AiTkF",
        "outputId": "5d3b09bb-c84a-400a-e68f-e3a4ca7ab472"
      },
      "outputs": [],
      "source": [
        "# CosPlace requirements\n",
        "!pip3 install \"faiss_cpu>=1.7.1\"\n",
        "!pip3 install \"numpy>=1.21.2\"\n",
        "!pip3 install \"Pillow>=9.0.1\"\n",
        "!pip3 install \"scikit_learn>=1.0.2\"\n",
        "!pip3 install \"torch>=1.8.2\"\n",
        "!pip3 install \"torchvision>=0.9.2\"\n",
        "!pip3 install \"tqdm>=4.62.3\"\n",
        "!pip3 install \"utm>=0.7.0\"\n",
        "\n",
        "import torch\n",
        "#use GPU if available \n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #'cpu' # 'cuda' or 'cpu'\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czjvnq3FjBmh"
      },
      "source": [
        "# Download Datasets and previous data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hY8bYPGyqLF"
      },
      "source": [
        "Downloading with gdown doesn't work properly.\n",
        "\n",
        "Prefer always to use drive / mount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGOhXMNqjMed",
        "outputId": "4c11717c-1818-4386-d3bd-48bb13bc2a47"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gdown\n",
        "from google.colab import drive\n",
        "\n",
        "def download(id, output=None, quiet=True):\n",
        "  gdown.download(\n",
        "    f\"https://drive.google.com/uc?export=download&confirm=pbef&id={id}\",\n",
        "    output=output,\n",
        "    quiet=quiet\n",
        "  )\n",
        "\n",
        "\n",
        "use_mount = True\n",
        "resume_model = False\n",
        "\n",
        "if use_mount:\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "# TOKYO-XS DATASET\n",
        "if not os.path.isdir(\"/content/tokyo_xs\"):\n",
        "  if use_mount:\n",
        "    !jar xvf \"/content/drive/MyDrive/Project 6 - Dataset/tokyo-xs.zip\"\n",
        "  else:\n",
        "    id = \"1fBCnap5BRh36474cVkjvjlC-yUTEb1n3\"\n",
        "    download(id, quiet=False)                           # download from our gdrive\n",
        "    !jar xvf \"/content/tokyo-xs.zip\"                    # unzip\n",
        "    !rm -r \"/content/tokyo-xs.zip\"                      # remove .zip file\n",
        "\n",
        "if not os.path.isdir(\"/content/tokyo_xs\"):\n",
        "  raise FileNotFoundError(f\"Can't download tokyo xs\")\n",
        "\n",
        "#TOKYO NIGHT DATASET\n",
        "if not os.path.isdir(\"/content/tokyo-night\"):\n",
        "  if use_mount:\n",
        "    !jar xvf \"/content/drive/MyDrive/Project 6 - Dataset/tokyo-night.zip\"\n",
        "  else:\n",
        "    id = \"1EZJY2r5565-iVk2oEbTns0xc4F_em4Y4\"\n",
        "    download(id, quiet=False)                           # download from our gdrive\n",
        "    !jar xvf \"/content/tokyo-night.zip\"                    # unzip\n",
        "    !rm -r \"/content/tokyo-night.zip\"\n",
        "\n",
        "if not os.path.isdir(\"/content/tokyo-night\"):\n",
        "  raise FileNotFoundError(f\"Can't download tokyo night\")\n",
        "\n",
        "# SAN FRANCISCO - XS DATASET\n",
        "if not os.path.isdir(\"/content/small\"):\n",
        "  if use_mount:\n",
        "    !jar xvf \"/content/drive/MyDrive/Project 6 - Dataset/sf-xs.zip\"\n",
        "  else:\n",
        "    id = \"1brIxBJmOgvuzFbI57f5LxnMxjccUu993\"\n",
        "    download(id, quiet=False)                           # download\n",
        "    !jar xvf \"/content/sf-xs.zip\"                       # unzip\n",
        "    !rm -r \"/content/sf-xs.zip\"                         # remove .zip file\n",
        "\n",
        "if not os.path.isdir(\"/content/small\"):\n",
        "  raise FileNotFoundError(f\"Can't download sfxs\")\n",
        "\n",
        "# resumed model\n",
        "if resume_model and not os.path.isfile(\"/content/saved_models/arcface_model.pth\"):\n",
        "  if use_mount:\n",
        "    !jar xvf \"/content/drive/MyDrive/Project 6 - Dataset/saved_models.zip\"\n",
        "\n",
        "if resume_model and not os.path.isfile(\"/content/saved_models/sphereface_model.pth\"):\n",
        "  if use_mount:\n",
        "    !jar xvf \"/content/drive/MyDrive/Project 6 - Dataset/saved_models.zip\"\n",
        "\n",
        "if resume_model and not os.path.isfile(\"/content/saved_models/cosface_model.pth\"):\n",
        "  if use_mount:\n",
        "    !jar xvf \"/content/drive/MyDrive/Project 6 - Dataset/saved_models.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g6SkCgyhl-g"
      },
      "source": [
        "# Download Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFrIIf6E0UQM"
      },
      "source": [
        "Clone of original repo of CosPlace and our code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63SgJ_Y0hwrC",
        "outputId": "fed6492f-479d-403e-bd7f-433482628191"
      },
      "outputs": [],
      "source": [
        "# download code of CosPlace\n",
        "!git clone \"https://github.com/gmberton/CosPlace\" \n",
        "#!rm -r \"/content/CosPlace\"\n",
        "\n",
        "# download our code\n",
        "!git clone --single-branch --branch \"sam\" \"https://github.com/gab-palmeri/aml-geolocalization.git\"\n",
        "!mv \"/content/aml-geolocalization/\" \"/content/Team\"\n",
        "#!rm -r \"/content/aml-geolocalization\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiwWzjzSio-h"
      },
      "source": [
        "\n",
        "\n",
        "# Import Code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAd54tr_cNtO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import logging\n",
        "import multiprocessing\n",
        "import numpy as np\n",
        "import torchvision.transforms as T\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "sys.path.append(\"/content/CosPlace/\")\n",
        "sys.path.append(\"/content/Team/\")\n",
        "import CosPlace\n",
        "from CosPlace import *\n",
        "\n",
        "torch.backends.cudnn.benchmark = True  # Provides a speedup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MsFj6mmaYJs"
      },
      "source": [
        "This class let us to access to dictionary keys like `dict.key` instead of `dict[\"key\"]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKoLeQ_1xGAA"
      },
      "outputs": [],
      "source": [
        "class dotdict(dict):\n",
        "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
        "    __getattr__ = dict.get\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb9otl0RvDI3"
      },
      "source": [
        "Drive related functions to save and load training checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcM7DpMovDI3",
        "outputId": "8d521311-3cd9-4ac0-fae9-07c4c60336d5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def drive_save_checkpoint(output_folder, time):\n",
        "    drive_folder = \"/content/drive/MyDrive/project6/\"\n",
        "    if not os.path.exists(drive_folder):\n",
        "        !mkdir \"/content/drive/MyDrive/project6/\"\n",
        "    !zip -r \"/content/drive/MyDrive/project6/{time}.zip\" \"/content/{output_folder}\"\n",
        "\n",
        "def drive_load_checkpoint(input_folder, time):\n",
        "    drive_folder = \"/content/drive/MyDrive/project6/\"\n",
        "    !jar xvf \"/content/drive/MyDrive/project6/{time}.zip\"\n",
        "\n",
        "def drive_tester(output_folder):\n",
        "    drive_folder = \"/content/drive/MyDrive/project6/\"\n",
        "    if not os.path.exists(drive_folder):\n",
        "        !mkdir \"/content/drive/MyDrive/project6/\"\n",
        "    !touch \"/content/drive/MyDrive/project6/test\"\n",
        "\n",
        "    if os.path.exists(\"/content/drive/MyDrive/project6/test\"):\n",
        "        logging.info(\"Drive saving works\")\n",
        "    else:\n",
        "        logging.info(\"WARNING: Drive saving does not work\")\n",
        "\n",
        "# use this function when content on drive are not updated\n",
        "def drive_refresh():\n",
        "  drive.flush_and_unmount()\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpbRF7uZxGAB"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_UnO_6a0amb"
      },
      "source": [
        "Original code provides two main executable files: `train.py` and `eval.py`. We want to reproduce the same behaviour of these two files so these are the parameters passed via terminal. They will be put in a dict called `args` to simply reuse code inside ex files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tOcIQ1Fwni7"
      },
      "source": [
        "## Setup parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sI0BfY2_xGAB"
      },
      "outputs": [],
      "source": [
        "# CosPlace Groups parameters\n",
        "COS_M = 10\n",
        "ALPHA = 30\n",
        "COS_N = 5\n",
        "COS_L = 2\n",
        "GROUPS_NUM = 1\n",
        "MIN_IMAGES_PER_CLASS = 10\n",
        "# Model parameters\n",
        "BACKBONE = \"resnet18\"   \n",
        "# [\"resnet18\", \"efficientnet_b2\", \"efficientnet_v2_s\", \"mobilenet_v3_small\", \"mobilenet_v3_large\",\n",
        "# [\"convnext_tiny\", \"swin_tiny\", \"cct384\"]\n",
        "FC_OUTPUT_DIM = 512     # Output dimension of final fully connected layer\n",
        "PRETRAIN = \"imagenet\"   # [\"imagenet\", \"places\", \"gldv2\"]\n",
        "# Training parameters\n",
        "AUGMENTATION_DEVICE = \"cuda\"    # [\"cuda\", \"cpu\"]\n",
        "USE_AMP_16 = AUGMENTATION_DEVICE == \"cuda\"       # use Automatic Mixed Precision\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS_NUM = 3\n",
        "ITERATIONS_PER_EPOCH = 10_000\n",
        "LR = 0.00001                    # Learning rate  \n",
        "CLASSIFIERS_LR = 0.01\n",
        "# Data augmentation\n",
        "RESIZE_AS_DB = False\n",
        "BRIGHTNESS = 0.7\n",
        "CONTRAST = 0.7\n",
        "SATURATION = 0.7\n",
        "HUE = 0.5\n",
        "RANDOM_RESIZED_CROP = 0.5\n",
        "RANDOM_H_FLIP = False\n",
        "MAJORITY_WEIGHT = 0.01\n",
        "# Validation / test parameters\n",
        "INFER_BATCH_SIZE = 16           # Batch size for inference (validating and testing)\n",
        "POSITIVE_DIST_THRESHOLD = 25    # distance in meters for a prediction to be considered a positive\n",
        "# Resume parameters\n",
        "RESUME_TRAIN = None     # path to checkpoint to resume, e.g. logs/.../last_checkpoint.pth\n",
        "RESUME_MODEL = None     # Path to model to resume training from\n",
        "# Other parameters\n",
        "DEVICE = \"cuda\"                     # [\"cuda\", \"cpu\"]\n",
        "SEED = 0\n",
        "NUM_WORKERS = 8\n",
        "DATASET_FOLDER = \"/content/small\"   # path of the folder with train/val sets\n",
        "SAVEDIR = BACKBONE + \"_\" + PRETRAIN\n",
        "TEST_METHOD = None\n",
        "\n",
        "\n",
        "if not os.path.exists(DATASET_FOLDER):\n",
        "    raise FileNotFoundError(f\"Dataset folder {DATASET_FOLDER} not found\")\n",
        "\n",
        "train_set_folder = os.path.join(DATASET_FOLDER, \"train\")\n",
        "\n",
        "if not os.path.exists(train_set_folder):\n",
        "    raise FileNotFoundError(f\"Train set folder {train_set_folder} not found\")\n",
        "\n",
        "val_set_folder = os.path.join(DATASET_FOLDER, \"val\")\n",
        "\n",
        "if not os.path.exists(val_set_folder):\n",
        "    raise FileNotFoundError(f\"Validation set folder {val_set_folder} not found\")\n",
        "\n",
        "if BACKBONE != \"resnet18\" and PRETRAIN != \"imagenet\":\n",
        "    raise ValueError(\"Only resnet18 can be pretrained on other datasets than ImageNet\")\n",
        "\n",
        "# dictionary for the parameters\n",
        "args = {\n",
        "    'M': COS_M, 'alpha': ALPHA, 'N': COS_N, 'L': COS_L, 'groups_num': GROUPS_NUM,\n",
        "    'min_images_per_class': MIN_IMAGES_PER_CLASS, 'backbone': BACKBONE, \"pretrain\": PRETRAIN,\n",
        "    'fc_output_dim': FC_OUTPUT_DIM, 'use_amp16': USE_AMP_16,\n",
        "    'augmentation_device': AUGMENTATION_DEVICE, 'batch_size': BATCH_SIZE,\n",
        "    'epochs_num': EPOCHS_NUM, 'iterations_per_epoch': ITERATIONS_PER_EPOCH,\n",
        "    'lr': LR, 'classifiers_lr': CLASSIFIERS_LR, 'brightness': BRIGHTNESS, 'resize_as_db': RESIZE_AS_DB,\n",
        "    'contrast': CONTRAST, 'hue': HUE, 'saturation': SATURATION, 'hflip': RANDOM_H_FLIP, 'maj_weight': MAJORITY_WEIGHT,\n",
        "    'random_resized_crop': RANDOM_RESIZED_CROP, 'infer_batch_size': INFER_BATCH_SIZE,\n",
        "    'positive_dist_threshold': POSITIVE_DIST_THRESHOLD, 'resume_train': RESUME_TRAIN,\n",
        "    'resume_model': RESUME_MODEL, 'device': DEVICE, 'seed': SEED,\n",
        "    'num_workers': NUM_WORKERS, 'dataset_folder': DATASET_FOLDER, 'save_dir': SAVEDIR,\n",
        "    'val_set_folder': val_set_folder, 'train_set_folder': train_set_folder, 'test_method': TEST_METHOD\n",
        "}\n",
        "\n",
        "# this helps to reuse the code from the original CosPlace\n",
        "args = dotdict(args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "saveDirLocal = SAVEDIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weAbHrt3PsA3"
      },
      "source": [
        "# Setup logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF4OSAc0PsA3",
        "outputId": "9a3b8b28-b974-47e8-d29e-16ecaf7200e9"
      },
      "outputs": [],
      "source": [
        "from CosPlace import commons\n",
        "\n",
        "start_time = datetime.now()\n",
        "output_folder = f\"logs/{args.save_dir}/{start_time.strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
        "commons.make_deterministic(args.seed)\n",
        "commons.setup_logging(output_folder, console=None)\n",
        "logging.info(\" \".join(sys.argv))\n",
        "logging.info(f\"Arguments: {args}\")\n",
        "logging.info(f\"The outputs are being saved in {output_folder}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_21_ceryD9G"
      },
      "source": [
        "# PAY ATTENTION!\n",
        "If you want to just test an already provided model, you should skip the training part and go to [Test section](#scrollTo=Y5jJf7v5Ox91)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5jJf7v5Ox91"
      },
      "source": [
        "# Model soup"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6ItObSaBl6ox"
      },
      "source": [
        "## Setup folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir /content/soup_models"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Move all the file that you want to put in the soup in the folder `soup_models`, then run the following cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "weights_dir = \"/content/soup_models\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "datasets_map = {\n",
        "  # put here the paths of the datasets that you want to use to evaluate the model\n",
        "  \"sf-val\": \"path/to/sf_val\",\n",
        "  \"sf-xs\": \"path/to/sf_xs\",\n",
        "  \"tokyo-xs\": \"path/to/tokyo_xs\",\n",
        "  \"tokyo-night\": \"path/to/tokyo_night\",\n",
        "}\n",
        "\n",
        "for x in datasets_map:\n",
        "  if not os.path.exists(datasets_map[x]):\n",
        "    raise FileNotFoundError(f\"Dataset folder {x} not found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate individual models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzJGjw9xxGAE",
        "outputId": "47627e4e-c4a2-42fb-8cb4-9f959c28c2ab"
      },
      "outputs": [],
      "source": [
        "import Team.ensemble.model_soup as ms\n",
        "from Team.model import network\n",
        "\n",
        "\n",
        "individual_results = ms.evaluate_individual_models(args, weights_dir, datasets_map)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save the results in a json file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "ready_to_json = {}\n",
        "for k in individual_results:\n",
        "  inner = {}\n",
        "  for k_inner in individual_results[k]:\n",
        "    inner[k_inner] = individual_results[k][k_inner].tolist()\n",
        "  ready_to_json[k] = inner\n",
        "with open(\"individual_results.json\", 'w') as f:\n",
        "  f.write(json.dumps(ready_to_json))\n",
        "\n",
        "logging.info(\"Saved individual results to json at path /content/individual_results.json\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load individual results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "json_string = ''\n",
        "with open('/content/individual_results.json', 'r') as f:\n",
        "  json_string = f.readline()\n",
        "individual_results = json.loads(json_string)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Do greedy soup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "greedy_soup_results, greedy_soup_ingredients = ms.greedy_soup(args, weights_dir, datasets_map, individual_results, sort_by=\"tn_r5\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate greedy soup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "logging.info(f\"Greedy soup ingredients: {greedy_soup_ingredients}\")\n",
        "logging.info(f\"Greedy soup results: {greedy_soup_results}\")\n",
        "if args.add_to_greedy_soup:\n",
        "    logging.info(\"Testing the greedy soup with the new model\")\n",
        "    test_results = ms.evaluate_greedy_soup(args, datasets_map, greedy_soup_ingredients)\n",
        "else:\n",
        "    logging.info(\"Greedy soup don't add anything to original results\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQXOjFvsweIa"
      },
      "source": [
        "## Save on Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPIfX1yp_dtj"
      },
      "source": [
        "Save all data generated by this notebook in a specific folder in **PERSONAL** gdrive. Remember to copy inside shared_data of project drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyLTpYMh2iYG",
        "outputId": "b4c3cbdc-7b54-4006-b888-0846190ca262"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# zip logs -> logs.zip\n",
        "!zip -r f\"/content/{SAVEDIR}/logs.zip\" /content/logs/\n",
        "\n",
        "if args.add_to_greedy_soup:\n",
        "  torch.save(greedy_soup_ingredients, f\"/content/{SAVEDIR}/{args.backbone}greedy_soup_ingredients.pth\")\n",
        "  with open(f\"/content/{SAVEDIR}/soup.json\", \"w\") as f:\n",
        "    f.write(json.dumps(greedy_soup_results))\n",
        "\n",
        "  !cp f\"/content/{SAVEDIR}/soup.json\" /content/drive/MyDrive/project6/\n",
        "  !cp f\"/content/{SAVEDIR}/{args.backbone}greedy_soup_ingredients.pth\" /content/drive/MyDrive/project6/\n",
        "\n",
        "!cp \"/content/{SAVEDIR}/logs.zip\" /content/drive/MyDrive/project6/\n",
        "\n",
        "drive.flush_and_unmount()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "qf3z5SqWZ91b"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8 (default, Apr 13 2021, 12:59:45) \n[Clang 10.0.0 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
