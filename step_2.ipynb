{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gab-palmeri/aml-geolocalization/blob/sam/step_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n18u6OFZxF_z"
      },
      "source": [
        "The purpose of this notebook is to test the default model on three different datasets. The first is sf-xs test, the second is tokyo-xs test, and the last one is tokyo-night, a subset of the tokyo dataset with only night images as query images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf3z5SqWZ91b"
      },
      "source": [
        "# pip install requirements "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "id": "YbtEmI1AiTkF",
        "outputId": "b9c2cbb9-98b1-4a77-ef66-96a148a94c79"
      },
      "outputs": [],
      "source": [
        "# CosPlace requirements\n",
        "!pip3 install \"faiss_cpu>=1.7.1\"\n",
        "!pip3 install \"numpy>=1.21.2\"\n",
        "!pip3 install \"Pillow>=9.0.1\"\n",
        "!pip3 install \"scikit_learn>=1.0.2\"\n",
        "!pip3 install \"torch>=1.8.2\"\n",
        "!pip3 install \"torchvision>=0.9.2\"\n",
        "!pip3 install \"tqdm>=4.62.3\"\n",
        "!pip3 install \"utm>=0.7.0\"\n",
        "\n",
        "import torch\n",
        "#use GPU if available \n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #'cpu' # 'cuda' or 'cpu'\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czjvnq3FjBmh"
      },
      "source": [
        "# Download Datasets and previous data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGOhXMNqjMed",
        "outputId": "9a635f14-3e51-4c45-c320-fcee9bff83ae"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gdown\n",
        "\n",
        "def download(id, output=None, quiet=True):\n",
        "  gdown.download(\n",
        "    f\"https://drive.google.com/uc?export=download&confirm=pbef&id={id}\",\n",
        "    output=output,\n",
        "    quiet=quiet\n",
        "  )\n",
        "\n",
        "# TOKYO-XS DATASET\n",
        "if not os.path.isdir(\"/content/tokyo_xs\"):\n",
        "  id = \"1fBCnap5BRh36474cVkjvjlC-yUTEb1n3\"\n",
        "  download(id, quiet=False)                           # download from our gdrive\n",
        "  !jar xvf \"/content/tokyo-xs.zip\"                    # unzip\n",
        "  !rm -r \"/content/tokyo-xs.zip\"                      # remove .zip file\n",
        "\n",
        "# TOKYO NIGHT DATASET\n",
        "# if not os.path.isdir(\"/content/tokyo_night\"):\n",
        "# id = \"tokyo_night_id\"\n",
        "#  download(id, quiet=False)                           # download from our gdrive\n",
        "#  !jar xvf \"/content/tokyo-night.zip\"                    # unzip\n",
        "#  !rm -r \"/content/tokyo-night.zip\"  \n",
        "\n",
        "# SAN FRANCISCO - XS DATASET\n",
        "if not os.path.isdir(\"/content/small\"):\n",
        "  id = \"1brIxBJmOgvuzFbI57f5LxnMxjccUu993\"\n",
        "  download(id, quiet=False)                           # download\n",
        "  !jar xvf \"/content/sf-xs.zip\"                       # unzip\n",
        "  !rm -r \"/content/sf-xs.zip\"                         # remove .zip file\n",
        "\n",
        "\n",
        "# CACHE\n",
        "if not os.path.isdir(\"/content/cache\"):\n",
        "  id = \"1J6InuF4I_OsiuwvVPRrwDfP-W2nz8Kn0\"\n",
        "  download(id, quiet=False)                           # download\n",
        "  !jar xvf \"/content/cache.zip\"                       # unzip\n",
        "  !cp -r \"/content/content/cache/.\" \"/content/cache/\" # copy in main dir\n",
        "  !rm -rf \"/content/content/\"                         # remove old dir\n",
        "  !rm -r \"/content/cache.zip\"                         # remove .zip file\n",
        "\n",
        "# LOGS\n",
        "if not os.path.isdir(\"/content/logs\"):\n",
        "  id = \"1q9x_SGDJxO3D-niFyOe5inkoO-8ONHcW\"\n",
        "  download(id, quiet=False)                           # download\n",
        "  !jar xvf \"/content/logs.zip\"                        # unzip\n",
        "  !cp -r \"/content/content/logs/.\" \"/content/logs/\"   # copy in main dir\n",
        "  !rm -rf \"/content/content/\"                         # remove old dir\n",
        "  !rm -r \"/content/logs.zip\"                          # remove .zip file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g6SkCgyhl-g"
      },
      "source": [
        "# Download Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63SgJ_Y0hwrC",
        "outputId": "41ef6481-3dee-4e36-ca67-27e6ca3c500a"
      },
      "outputs": [],
      "source": [
        "# download code of CosPlace\n",
        "!git clone \"https://github.com/gmberton/CosPlace\" \n",
        "#!rm -r \"/content/CosPlace\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiwWzjzSio-h"
      },
      "source": [
        "\n",
        "\n",
        "# Import Code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iAd54tr_cNtO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import logging\n",
        "import multiprocessing\n",
        "import numpy as np\n",
        "import torchvision.transforms as T\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "sys.path.append(\"/content/CosPlace/\")\n",
        "\n",
        "import CosPlace\n",
        "from CosPlace import *\n",
        "\n",
        "torch.backends.cudnn.benchmark = True  # Provides a speedup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MsFj6mmaYJs"
      },
      "source": [
        "This class let us to access to dictionary keys like `dict.key` instead of `dict[\"key\"]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PKoLeQ_1xGAA"
      },
      "outputs": [],
      "source": [
        "class dotdict(dict):\n",
        "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
        "    __getattr__ = dict.get\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpbRF7uZxGAB"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sI0BfY2_xGAB"
      },
      "outputs": [],
      "source": [
        "# CosPlace Groups parameters\n",
        "COS_M = 10\n",
        "ALPHA = 30\n",
        "COS_N = 5\n",
        "COS_L = 2\n",
        "GROUPS_NUM = 1\n",
        "MIN_IMAGES_PER_CLASS = 10\n",
        "# Model parameters\n",
        "BACKBONE = \"resnet18\"   # [\"vgg16\", \"resnet18\", \"resnet50\", \"resnet101\", \"resnet152\"]\n",
        "FC_OUTPUT_DIM = 512     # Output dimension of final fully connected layer\n",
        "# Training parameters\n",
        "USE_AMP_16 = \"store_true\"       # use Automatic Mixed Precision\n",
        "AUGMENTATION_DEVICE = \"cuda\"    # [\"cuda\", \"cpu\"]\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS_NUM = 3\n",
        "ITERATIONS_PER_EPOCH = 10_000\n",
        "LR = 0.00001                    # Learning rate  \n",
        "CLASSIFIERS_LR = 0.01\n",
        "# Data augmentation\n",
        "BRIGHTNESS = 0.7\n",
        "CONTRAST = 0.7\n",
        "SATURATION = 0.7\n",
        "HUE = 0.5\n",
        "RANDOM_RESIZED_CROP = 0.5\n",
        "# Validation / test parameters\n",
        "INFER_BATCH_SIZE = 16           # Batch size for inference (validating and testing)\n",
        "POSITIVE_DIST_THRESHOLD = 25    # distance in meters for a prediction to be considered a positive\n",
        "# Resume parameters\n",
        "RESUME_TRAIN = None     # path to checkpoint to resume, e.g. logs/.../last_checkpoint.pth\n",
        "RESUME_MODEL = None     # Path to model to resume training from\n",
        "# Other parameters\n",
        "DEVICE = \"cuda\"                     # [\"cuda\", \"cpu\"]\n",
        "SEED = 0\n",
        "NUM_WORKERS = 8\n",
        "DATASET_FOLDER = \"/content/small\"   # path of the folder with train/val sets\n",
        "SAVEDIR = \"default\"\n",
        "\n",
        "\n",
        "if not os.path.exists(DATASET_FOLDER):\n",
        "    raise FileNotFoundError(f\"Dataset folder {DATASET_FOLDER} not found\")\n",
        "\n",
        "train_set_folder = os.path.join(DATASET_FOLDER, \"train\")\n",
        "\n",
        "if not os.path.exists(train_set_folder):\n",
        "    raise FileNotFoundError(f\"Train set folder {train_set_folder} not found\")\n",
        "\n",
        "val_set_folder = os.path.join(DATASET_FOLDER, \"val\")\n",
        "\n",
        "if not os.path.exists(val_set_folder):\n",
        "    raise FileNotFoundError(f\"Validation set folder {val_set_folder} not found\")\n",
        "\n",
        "\n",
        "# dictionary for the parameters\n",
        "args = {\n",
        "    'M': COS_M, 'alpha': ALPHA, 'N': COS_N, 'L': COS_L, 'groups_num': GROUPS_NUM,\n",
        "    'min_images_per_class': MIN_IMAGES_PER_CLASS, 'backbone': BACKBONE,\n",
        "    'fc_output_dim': FC_OUTPUT_DIM, 'use_amp_16': USE_AMP_16,\n",
        "    'augmentation_device': AUGMENTATION_DEVICE, 'batch_size': BATCH_SIZE,\n",
        "    'epochs_num': EPOCHS_NUM, 'iterations_per_epoch': ITERATIONS_PER_EPOCH,\n",
        "    'lr': LR, 'classifiers_lr': CLASSIFIERS_LR, 'brightness': BRIGHTNESS,\n",
        "    'contrast': CONTRAST, 'hue': HUE, 'saturation': SATURATION,\n",
        "    'random_resized_crop': RANDOM_RESIZED_CROP, 'infer_batch_size': INFER_BATCH_SIZE,\n",
        "    'positive_dist_threshold': POSITIVE_DIST_THRESHOLD, 'resume_train': RESUME_TRAIN,\n",
        "    'resume_model': RESUME_MODEL, 'device': DEVICE, 'seed': SEED,\n",
        "    'num_workers': NUM_WORKERS, 'dataset_folder': DATASET_FOLDER, 'save_dir': SAVEDIR,\n",
        "    'val_set_folder': val_set_folder, 'train_set_folder': train_set_folder,\n",
        "}\n",
        "\n",
        "# this helps to reuse the code from the original CosPlace\n",
        "args = dotdict(args)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weAbHrt3PsA3"
      },
      "source": [
        "# Setup logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF4OSAc0PsA3",
        "outputId": "88b1a726-48bd-4cb7-92e4-dcea7dbb43bf"
      },
      "outputs": [],
      "source": [
        "from CosPlace import commons\n",
        "\n",
        "start_time = datetime.now()\n",
        "output_folder = f\"logs/{args.save_dir}/{start_time.strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
        "commons.make_deterministic(args.seed)\n",
        "commons.setup_logging(output_folder, console=None)\n",
        "logging.info(\" \".join(sys.argv))\n",
        "logging.info(f\"Arguments: {args}\")\n",
        "logging.info(f\"The outputs are being saved in {output_folder}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbHjiIS7xGAC"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxEATeZ0PsA3"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmFpttOdPsA3",
        "outputId": "fe0f7eaa-ad24-4e5c-81db-99215dd2a7f8"
      },
      "outputs": [],
      "source": [
        "from CosPlace import model\n",
        "from model import network\n",
        "\n",
        "model = network.GeoLocalizationNet(args.backbone, args.fc_output_dim)\n",
        "\n",
        "logging.info(f\"There are {torch.cuda.device_count()} GPUs and {multiprocessing.cpu_count()} CPUs.\")\n",
        "\n",
        "if args.resume_model is not None:\n",
        "    logging.debug(f\"Loading model from {args.resume_model}\")\n",
        "    model_state_dict = torch.load(args.resume_model)\n",
        "    model.load_state_dict(model_state_dict)\n",
        "\n",
        "model = model.to(args.device).train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYVmm3_wPsA3"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "MdqXRnxIPsA3"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "model_optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LIlc-xSPsA4"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEoGHYMVPsA4",
        "outputId": "2f401ccf-e13d-400d-fda9-a798d1c6629e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Using cached dataset cache/small_M10_N5_mipc10.torch\n",
            "INFO:root:Using 1 groups\n",
            "INFO:root:The 1 groups have respectively the following number of classes [5965]\n",
            "INFO:root:The 1 groups have respectively the following number of images [59650]\n",
            "INFO:root:Validation set: < val - #q: 7993; #db: 8015 >\n"
          ]
        }
      ],
      "source": [
        "from CosPlace import datasets, cosface_loss\n",
        "from datasets.train_dataset import TrainDataset\n",
        "from datasets.test_dataset import TestDataset\n",
        "\n",
        "groups = [TrainDataset(args, args.train_set_folder, M=args.M, alpha=args.alpha, N=args.N, L=args.L,\n",
        "                       current_group=n, min_images_per_class=args.min_images_per_class) for n in range(args.groups_num)]\n",
        "# Each group has its own classifier, which depends on the number of classes in the group\n",
        "classifiers = [cosface_loss.MarginCosineProduct(args.fc_output_dim, len(group)) for group in groups]\n",
        "classifiers_optimizers = [torch.optim.Adam(classifier.parameters(), lr=args.classifiers_lr) for classifier in classifiers]\n",
        "\n",
        "logging.info(f\"Using {len(groups)} groups\")\n",
        "logging.info(f\"The {len(groups)} groups have respectively the following number of classes {[len(g) for g in groups]}\")\n",
        "logging.info(f\"The {len(groups)} groups have respectively the following number of images {[g.get_images_num() for g in groups]}\")\n",
        "\n",
        "val_ds = TestDataset(args.val_set_folder, positive_dist_threshold=args.positive_dist_threshold)\n",
        "logging.info(f\"Validation set: {val_ds}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tNuFuBpNPsA4"
      },
      "source": [
        "## Resume train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "WxJEyKRzPsA4"
      },
      "outputs": [],
      "source": [
        "from CosPlace import util\n",
        "\n",
        "if args.resume_train:\n",
        "    model, model_optimizer, classifiers, classifiers_optimizers, best_val_recall1, start_epoch_num = \\\n",
        "        util.resume_train(args, output_folder, model, model_optimizer, classifiers, classifiers_optimizers)\n",
        "    model = model.to(args.device)\n",
        "    epoch_num = start_epoch_num - 1\n",
        "    logging.info(f\"Resuming from epoch {start_epoch_num} with best R@1 {best_val_recall1:.1f} from checkpoint {args.resume_train}\")\n",
        "else:\n",
        "    best_val_recall1 = start_epoch_num = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJnmjudfPsA4"
      },
      "source": [
        "## Train and Evaluation Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRWSj33fPsA4",
        "outputId": "bc1bbac9-038d-41f3-8ec6-70be7e30ae96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Start training ...\n",
            "INFO:root:There are 5965 classes for the first group, each epoch has 10 iterations with batch_size 32, therefore the model sees each class (on average) 0.1 times per epoch\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100%|███████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.22it/s]\n",
            "DEBUG:root:Epoch 00 in 0:00:08, loss = 39.6842\n",
            "DEBUG:root:Extracting database descriptors for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 501/501 [01:10<00:00,  7.10it/s]\n",
            "DEBUG:root:Extracting queries descriptors for evaluation/testing using batch size 1\n",
            "100%|███████████████████████████████████████████████████████████| 7993/7993 [02:04<00:00, 64.05it/s]\n",
            "DEBUG:root:Calculating recalls\n",
            "INFO:root:Epoch 00 in 0:03:25, < val - #q: 7993; #db: 8015 >: R@1: 30.2, R@5: 43.2\n",
            "INFO:root:Trained for 01 epochs, in total in 0:10:11\n"
          ]
        }
      ],
      "source": [
        "from CosPlace import augmentations, test\n",
        "\n",
        "logging.info(\"Start training ...\")\n",
        "logging.info(f\"There are {len(groups[0])} classes for the first group, \" +\n",
        "             f\"each epoch has {args.iterations_per_epoch} iterations \" +\n",
        "             f\"with batch_size {args.batch_size}, therefore the model sees each class (on average) \" +\n",
        "             f\"{args.iterations_per_epoch * args.batch_size / len(groups[0]):.1f} times per epoch\")\n",
        "\n",
        "\n",
        "if args.augmentation_device == \"cuda\":\n",
        "    gpu_augmentation = T.Compose([\n",
        "            augmentations.DeviceAgnosticColorJitter(brightness=args.brightness,\n",
        "                                                    contrast=args.contrast,\n",
        "                                                    saturation=args.saturation,\n",
        "                                                    hue=args.hue),\n",
        "            augmentations.DeviceAgnosticRandomResizedCrop([512, 512],\n",
        "                                                          scale=[1-args.random_resized_crop, 1]),\n",
        "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "if args.use_amp16:\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "for epoch_num in range(start_epoch_num, args.epochs_num):\n",
        "    \n",
        "    #### Train\n",
        "    epoch_start_time = datetime.now()\n",
        "    # Select classifier and dataloader according to epoch\n",
        "    current_group_num = epoch_num % args.groups_num\n",
        "    classifiers[current_group_num] = classifiers[current_group_num].to(args.device)\n",
        "    util.move_to_device(classifiers_optimizers[current_group_num], args.device)\n",
        "    \n",
        "    dataloader = commons.InfiniteDataLoader(groups[current_group_num], num_workers=args.num_workers,\n",
        "                                            batch_size=args.batch_size, shuffle=True,\n",
        "                                            pin_memory=(args.device == \"cuda\"), drop_last=True)\n",
        "    \n",
        "    dataloader_iterator = iter(dataloader)\n",
        "    model = model.train()\n",
        "    \n",
        "    epoch_losses = np.zeros((0, 1), dtype=np.float32)\n",
        "    for iteration in tqdm(range(args.iterations_per_epoch), ncols=100):\n",
        "        images, targets, _ = next(dataloader_iterator)\n",
        "        images, targets = images.to(args.device), targets.to(args.device)\n",
        "        \n",
        "        if args.augmentation_device == \"cuda\":\n",
        "            images = gpu_augmentation(images)\n",
        "        \n",
        "        model_optimizer.zero_grad()\n",
        "        classifiers_optimizers[current_group_num].zero_grad()\n",
        "        \n",
        "        if not args.use_amp16:\n",
        "            descriptors = model(images)\n",
        "            output = classifiers[current_group_num](descriptors, targets)\n",
        "            loss = criterion(output, targets)\n",
        "            loss.backward()\n",
        "            epoch_losses = np.append(epoch_losses, loss.item())\n",
        "            del loss, output, images\n",
        "            model_optimizer.step()\n",
        "            classifiers_optimizers[current_group_num].step()\n",
        "        else:  # Use AMP 16\n",
        "            with torch.cuda.amp.autocast():\n",
        "                descriptors = model(images)\n",
        "                output = classifiers[current_group_num](descriptors, targets)\n",
        "                loss = criterion(output, targets)\n",
        "            scaler.scale(loss).backward()\n",
        "            epoch_losses = np.append(epoch_losses, loss.item())\n",
        "            del loss, output, images\n",
        "            scaler.step(model_optimizer)\n",
        "            scaler.step(classifiers_optimizers[current_group_num])\n",
        "            scaler.update()\n",
        "    \n",
        "    classifiers[current_group_num] = classifiers[current_group_num].cpu()\n",
        "    util.move_to_device(classifiers_optimizers[current_group_num], \"cpu\")\n",
        "    \n",
        "    logging.debug(f\"Epoch {epoch_num:02d} in {str(datetime.now() - epoch_start_time)[:-7]}, \"\n",
        "                  f\"loss = {epoch_losses.mean():.4f}\")\n",
        "    \n",
        "    #### Evaluation\n",
        "    recalls, recalls_str = test.test(args, val_ds, model)\n",
        "    logging.info(f\"Epoch {epoch_num:02d} in {str(datetime.now() - epoch_start_time)[:-7]}, {val_ds}: {recalls_str[:20]}\")\n",
        "    is_best = recalls[0] > best_val_recall1\n",
        "    best_val_recall1 = max(recalls[0], best_val_recall1)\n",
        "    # Save checkpoint, which contains all training parameters\n",
        "    util.save_checkpoint({\n",
        "        \"epoch_num\": epoch_num + 1,\n",
        "        \"model_state_dict\": model.state_dict(),\n",
        "        \"optimizer_state_dict\": model_optimizer.state_dict(),\n",
        "        \"classifiers_state_dict\": [c.state_dict() for c in classifiers],\n",
        "        \"optimizers_state_dict\": [c.state_dict() for c in classifiers_optimizers],\n",
        "        \"best_val_recall1\": best_val_recall1\n",
        "    }, is_best, output_folder)\n",
        "\n",
        "\n",
        "logging.info(f\"Trained for {epoch_num+1:02d} epochs, in total in {str(datetime.now() - start_time)[:-7]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5jJf7v5Ox91"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ItObSaBl6ox"
      },
      "source": [
        "## Import model from logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzJGjw9xxGAE",
        "outputId": "b775753c-066c-41f6-8bf4-3e3dceaa5d12"
      },
      "outputs": [],
      "source": [
        "\n",
        "#### Model\n",
        "model = network.GeoLocalizationNet(args.backbone, args.fc_output_dim)\n",
        "\n",
        "logging.info(f\"There are {torch.cuda.device_count()} GPUs and {multiprocessing.cpu_count()} CPUs.\")\n",
        "\n",
        "# set the path to the model you want to resume\n",
        "# the following line will take the model trained here\n",
        "resume_model = f\"/content/logs/default/{start_time.strftime('%Y-%m-%d_%H-%M-%S')}/best_model.pth\"\n",
        "if args.resume_model is not None:\n",
        "  if os.path.exists(args.resume_model):\n",
        "    resume_model = args.resume_model\n",
        "elif os.path.exists(resume_model):\n",
        "  logging.info(f\"Loading model from {resume_model}\")\n",
        "  model_state_dict = torch.load(resume_model)\n",
        "  model.load_state_dict(model_state_dict)\n",
        "else:\n",
        "    logging.info(\"WARNING: You didn't provide a path to resume the model (--resume_model parameter). \" +\n",
        "                 \"Evaluation will be computed using randomly initialized weights.\")\n",
        "\n",
        "model = model.to(args.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVEznMFwxGAE"
      },
      "source": [
        "## Test on SF-XS"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test the model on the sf-xs (test) dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XZjk3Z2O1m6",
        "outputId": "e13b64b1-b5ca-4882-fc18-8f0547d30448"
      },
      "outputs": [],
      "source": [
        "# dataset_folder is the same of the training\n",
        "test_set_folder = os.path.join(DATASET_FOLDER, \"test\")\n",
        "if not os.path.exists(test_set_folder):\n",
        "    raise FileNotFoundError(f\"Test set folder {test_set_folder} not found\")\n",
        "\n",
        "test_ds = TestDataset(test_set_folder, queries_folder=\"queries_v1\",\n",
        "                      positive_dist_threshold=args.positive_dist_threshold)\n",
        "\n",
        "recalls, recalls_str = test.test(args, test_ds, model)\n",
        "logging.info(f\"{test_ds}: {recalls_str}\")\n",
        "\n",
        "# recalls for csv file\n",
        "sf_xs_r15 = f\"{recalls[0]}/{recalls[1]}\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test on Tokyo-XS"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test the model on the tokyo-xs dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJgmqoCgPxwu",
        "outputId": "f8a943f2-7231-4512-a275-61fd6f23636c"
      },
      "outputs": [],
      "source": [
        "tokyo_xs_folder = \"/content/tokyo_xs\"\n",
        "test_set_folder = os.path.join(tokyo_xs_folder, \"test\")\n",
        "if not os.path.exists(test_set_folder):\n",
        "    raise FileNotFoundError(f\"Test set folder {test_set_folder} not found\")\n",
        "\n",
        "test_ds = TestDataset(test_set_folder,\n",
        "                      positive_dist_threshold=args.positive_dist_threshold)\n",
        "\n",
        "recalls, recalls_str = test.test(args, test_ds, model)\n",
        "logging.info(f\"{test_ds}: {recalls_str}\")\n",
        "\n",
        "# recalls for csv file\n",
        "tokyo_xs_r15 = f\"{recalls[0]}/{recalls[1]}\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test on Tokyo-Night"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test the model on the tokyo-night dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "H9Vzh7YNQrQa"
      },
      "outputs": [],
      "source": [
        "tokyo_night_folder = \"/content/tokyo_night\"\n",
        "test_set_folder = os.path.join(tokyo_night_folder, \"test\")\n",
        "if not os.path.exists(test_set_folder):\n",
        "    raise FileNotFoundError(f\"Test set folder {test_set_folder} not found\")\n",
        "\n",
        "test_ds = TestDataset(test_set_folder,\n",
        "                      positive_dist_threshold=args.positive_dist_threshold)\n",
        "\n",
        "recalls, recalls_str = test.test(args, test_ds, model)\n",
        "logging.info(f\"{test_ds}: {recalls_str}\")\n",
        "\n",
        "# recalls for csv file\n",
        "tokyo_night_r15 = f\"{recalls[0]}/{recalls[1]}\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6vPCrdJInVZ8"
      },
      "source": [
        "# Save results"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create CSV with recalls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_zxkamqncCt",
        "outputId": "c3b2bee6-45fd-41f3-f258-a46d62eb0fda"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "header = [\"sf-xs (test)\", \"Tokyo-xs\", \"Tokyo-night\"]\n",
        "data = [sf_xs_r15, tokyo_xs_r15, tokyo_night_r15]\n",
        "\n",
        "with open(f\"/content/{start_time.strftime('%Y-%m-%d_%H-%M-%S')}.csv\", \"w\") as f:\n",
        "  writer = csv.writer(f)\n",
        "\n",
        "  writer.writerow(header)\n",
        "  writer.writerow(data)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save on Drive"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wPIfX1yp_dtj"
      },
      "source": [
        "Save all data generated by this notebook in a specific folder in **PERSONAL** gdrive. Remember to copy inside shared_data of project drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnPzKaCQ-xRD",
        "outputId": "ff570806-f650-4bb4-dcef-7989007d3d87"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "if not os.path.exists(\"/content/drive/MyDrive/step_2\"):\n",
        "  !mkdir /content/drive/MyDrive/step_2\n",
        "\n",
        "# zip logs -> logs.zip\n",
        "!zip -r /content/drive/MyDrive/step_2/logs.zip /content/logs/\n",
        "# zip cache -> cache.zip\n",
        "!zip -r /content/drive/MyDrive/step_2/cache.zip /content/cache/\n",
        "\n",
        "!cp \"/content/{start_time.strftime('%Y-%m-%d_%H-%M-%S')}.csv\" /content/drive/MyDrive/step_2/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "qf3z5SqWZ91b",
        "czjvnq3FjBmh"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.8 (default, Apr 13 2021, 12:59:45) \n[Clang 10.0.0 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
