{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "n18u6OFZxF_z"
      },
      "source": [
        "The purpose of this notebook is to train the model with arcface and sphereface loss function and test with our databases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf3z5SqWZ91b"
      },
      "source": [
        "# pip install requirements\n",
        "\n",
        "Remember to click on \"Restart Runtime\" before go on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YbtEmI1AiTkF",
        "outputId": "9dd6ba4e-2dd9-40db-dc2e-f7fc53682f64"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/usr/bin/python3' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# CosPlace requirements\n",
        "!pip3 install \"faiss_cpu>=1.7.1\"\n",
        "!pip3 install \"numpy>=1.21.2\"\n",
        "!pip3 install \"Pillow>=9.0.1\"\n",
        "!pip3 install \"scikit_learn>=1.0.2\"\n",
        "!pip3 install \"torch>=1.8.2\"\n",
        "!pip3 install \"torchvision>=0.9.2\"\n",
        "!pip3 install \"tqdm>=4.62.3\"\n",
        "!pip3 install \"utm>=0.7.0\"\n",
        "\n",
        "import torch\n",
        "#use GPU if available \n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #'cpu' # 'cuda' or 'cpu'\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czjvnq3FjBmh"
      },
      "source": [
        "# Download Datasets and previous data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hY8bYPGyqLF"
      },
      "source": [
        "Downloading with gdown doesn't work properly.\n",
        "\n",
        "Prefer always to use drive / mount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGOhXMNqjMed",
        "outputId": "d56a2fd1-6e68-4eca-8db8-d4688be5fad6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gdown\n",
        "from google.colab import drive\n",
        "\n",
        "def download(id, output=None, quiet=True):\n",
        "  gdown.download(\n",
        "    f\"https://drive.google.com/uc?export=download&confirm=pbef&id={id}\",\n",
        "    output=output,\n",
        "    quiet=quiet\n",
        "  )\n",
        "\n",
        "\n",
        "use_mount = True\n",
        "resume_model = False\n",
        "\n",
        "if use_mount:\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "# TOKYO-XS DATASET\n",
        "if not os.path.isdir(\"/content/tokyo_xs\"):\n",
        "  if use_mount:\n",
        "    !jar xvf \"/content/drive/MyDrive/Project 6 - Dataset/tokyo-xs.zip\"\n",
        "  else:\n",
        "    id = \"1fBCnap5BRh36474cVkjvjlC-yUTEb1n3\"\n",
        "    download(id, quiet=False)                           # download from our gdrive\n",
        "    !jar xvf \"/content/tokyo-xs.zip\"                    # unzip\n",
        "    !rm -r \"/content/tokyo-xs.zip\"                      # remove .zip file\n",
        "\n",
        "#TOKYO NIGHT DATASET\n",
        "if not os.path.isdir(\"/content/tokyo_night\"):\n",
        "  if use_mount:\n",
        "    !jar xvf \"/content/drive/MyDrive/Project 6 - Dataset/tokyo-night.zip\"\n",
        "  else:\n",
        "    id = \"1EZJY2r5565-iVk2oEbTns0xc4F_em4Y4\"\n",
        "    download(id, quiet=False)                           # download from our gdrive\n",
        "    !jar xvf \"/content/tokyo-night.zip\"                    # unzip\n",
        "    !rm -r \"/content/tokyo-night.zip\"\n",
        "\n",
        "# SAN FRANCISCO - XS DATASET\n",
        "if not os.path.isdir(\"/content/small\"):\n",
        "  if use_mount:\n",
        "    !jar xvf \"/content/drive/MyDrive/Project 6 - Dataset/sf-xs.zip\"\n",
        "  else:\n",
        "    id = \"1brIxBJmOgvuzFbI57f5LxnMxjccUu993\"\n",
        "    download(id, quiet=False)                           # download\n",
        "    !jar xvf \"/content/sf-xs.zip\"                       # unzip\n",
        "    !rm -r \"/content/sf-xs.zip\"                         # remove .zip file\n",
        "\n",
        "# resumed model\n",
        "if resume_model and not os.path.isfile(\"/content/saved_models/arcface_model.pth\"):\n",
        "  if use_mount:\n",
        "    !jar xvf \"/content/drive/MyDrive/Project 6 - Dataset/saved_models.zip\"\n",
        "\n",
        "if resume_model and not os.path.isfile(\"/content/saved_models/sphereface_model.pth\"):\n",
        "  if use_mount:\n",
        "    !jar xvf \"/content/drive/MyDrive/Project 6 - Dataset/saved_models.zip\"\n",
        "\n",
        "if resume_model and not os.path.isfile(\"/content/saved_models/cosface_model.pth\"):\n",
        "  if use_mount:\n",
        "    !jar xvf \"/content/drive/MyDrive/Project 6 - Dataset/saved_models.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g6SkCgyhl-g"
      },
      "source": [
        "# Download Code"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VFrIIf6E0UQM"
      },
      "source": [
        "Clone of original repo of CosPlace and our code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63SgJ_Y0hwrC",
        "outputId": "c00333fa-73d3-4404-8f69-291e22af48e6"
      },
      "outputs": [],
      "source": [
        "# download code of CosPlace\n",
        "!git clone \"https://github.com/gmberton/CosPlace\" \n",
        "#!rm -r \"/content/CosPlace\"\n",
        "\n",
        "# download our code\n",
        "!git clone --single-branch --branch \"sam\" \"https://github.com/gab-palmeri/aml-geolocalization.git\"\n",
        "!mv \"/content/aml-geolocalization/\" \"/content/Team\"\n",
        "#!rm -r \"/content/aml-geolocalization\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiwWzjzSio-h"
      },
      "source": [
        "\n",
        "\n",
        "# Import Code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAd54tr_cNtO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import logging\n",
        "import multiprocessing\n",
        "import numpy as np\n",
        "import torchvision.transforms as T\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "sys.path.append(\"/content/CosPlace/\")\n",
        "sys.path.append(\"/content/Team/\")\n",
        "import CosPlace\n",
        "from CosPlace import *\n",
        "\n",
        "torch.backends.cudnn.benchmark = True  # Provides a speedup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MsFj6mmaYJs"
      },
      "source": [
        "This class let us to access to dictionary keys like `dict.key` instead of `dict[\"key\"]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKoLeQ_1xGAA"
      },
      "outputs": [],
      "source": [
        "class dotdict(dict):\n",
        "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
        "    __getattr__ = dict.get\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpbRF7uZxGAB"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_UnO_6a0amb"
      },
      "source": [
        "Original code provides two main executable files: `train.py` and `eval.py`. We want to reproduce the same behaviour of these two files so these are the parameters passed via terminal. They will be put in a dict called `args` to simply reuse code inside ex files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save dir for ArcFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "saveDirLocal = \"arcface\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save dir for SphereFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "saveDirLocal = \"sphereface\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save dir for CosFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "saveDirLocal = \"cosface\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sI0BfY2_xGAB"
      },
      "outputs": [],
      "source": [
        "# CosPlace Groups parameters\n",
        "COS_M = 10\n",
        "ALPHA = 30\n",
        "COS_N = 5\n",
        "COS_L = 2\n",
        "GROUPS_NUM = 1\n",
        "MIN_IMAGES_PER_CLASS = 10\n",
        "# Model parameters\n",
        "BACKBONE = \"resnet18\"   # [\"vgg16\", \"resnet18\", \"resnet50\", \"resnet101\", \"resnet152\"]\n",
        "FC_OUTPUT_DIM = 512     # Output dimension of final fully connected layer\n",
        "# Training parameters\n",
        "USE_AMP_16 = \"store_true\"       # use Automatic Mixed Precision\n",
        "AUGMENTATION_DEVICE = \"cuda\"    # [\"cuda\", \"cpu\"]\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS_NUM = 3\n",
        "ITERATIONS_PER_EPOCH = 10_000\n",
        "LR = 0.00001                    # Learning rate  \n",
        "CLASSIFIERS_LR = 0.01\n",
        "# Data augmentation\n",
        "BRIGHTNESS = 0.7\n",
        "CONTRAST = 0.7\n",
        "SATURATION = 0.7\n",
        "HUE = 0.5\n",
        "RANDOM_RESIZED_CROP = 0.5\n",
        "# Validation / test parameters\n",
        "INFER_BATCH_SIZE = 16           # Batch size for inference (validating and testing)\n",
        "POSITIVE_DIST_THRESHOLD = 25    # distance in meters for a prediction to be considered a positive\n",
        "# Resume parameters\n",
        "RESUME_TRAIN = None     # path to checkpoint to resume, e.g. logs/.../last_checkpoint.pth\n",
        "RESUME_MODEL = None     # Path to model to resume training from\n",
        "# Other parameters\n",
        "DEVICE = \"cuda\"                     # [\"cuda\", \"cpu\"]\n",
        "SEED = 0\n",
        "NUM_WORKERS = 8\n",
        "DATASET_FOLDER = \"/content/small\"   # path of the folder with train/val sets\n",
        "SAVEDIR = saveDirLocal\n",
        "\n",
        "\n",
        "if not os.path.exists(DATASET_FOLDER):\n",
        "    raise FileNotFoundError(f\"Dataset folder {DATASET_FOLDER} not found\")\n",
        "\n",
        "train_set_folder = os.path.join(DATASET_FOLDER, \"train\")\n",
        "\n",
        "if not os.path.exists(train_set_folder):\n",
        "    raise FileNotFoundError(f\"Train set folder {train_set_folder} not found\")\n",
        "\n",
        "val_set_folder = os.path.join(DATASET_FOLDER, \"val\")\n",
        "\n",
        "if not os.path.exists(val_set_folder):\n",
        "    raise FileNotFoundError(f\"Validation set folder {val_set_folder} not found\")\n",
        "\n",
        "\n",
        "# dictionary for the parameters\n",
        "args = {\n",
        "    'M': COS_M, 'alpha': ALPHA, 'N': COS_N, 'L': COS_L, 'groups_num': GROUPS_NUM,\n",
        "    'min_images_per_class': MIN_IMAGES_PER_CLASS, 'backbone': BACKBONE,\n",
        "    'fc_output_dim': FC_OUTPUT_DIM, 'use_amp_16': USE_AMP_16,\n",
        "    'augmentation_device': AUGMENTATION_DEVICE, 'batch_size': BATCH_SIZE,\n",
        "    'epochs_num': EPOCHS_NUM, 'iterations_per_epoch': ITERATIONS_PER_EPOCH,\n",
        "    'lr': LR, 'classifiers_lr': CLASSIFIERS_LR, 'brightness': BRIGHTNESS,\n",
        "    'contrast': CONTRAST, 'hue': HUE, 'saturation': SATURATION,\n",
        "    'random_resized_crop': RANDOM_RESIZED_CROP, 'infer_batch_size': INFER_BATCH_SIZE,\n",
        "    'positive_dist_threshold': POSITIVE_DIST_THRESHOLD, 'resume_train': RESUME_TRAIN,\n",
        "    'resume_model': RESUME_MODEL, 'device': DEVICE, 'seed': SEED,\n",
        "    'num_workers': NUM_WORKERS, 'dataset_folder': DATASET_FOLDER, 'save_dir': SAVEDIR,\n",
        "    'val_set_folder': val_set_folder, 'train_set_folder': train_set_folder,\n",
        "}\n",
        "\n",
        "# this helps to reuse the code from the original CosPlace\n",
        "args = dotdict(args)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weAbHrt3PsA3"
      },
      "source": [
        "# Setup logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF4OSAc0PsA3",
        "outputId": "44820aac-d933-485f-b509-23afcf67cf12"
      },
      "outputs": [],
      "source": [
        "from CosPlace import commons\n",
        "\n",
        "start_time = datetime.now()\n",
        "output_folder = f\"logs/{args.save_dir}/{start_time.strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
        "commons.make_deterministic(args.seed)\n",
        "commons.setup_logging(output_folder, console=None)\n",
        "logging.info(\" \".join(sys.argv))\n",
        "logging.info(f\"Arguments: {args}\")\n",
        "logging.info(f\"The outputs are being saved in {output_folder}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_21_ceryD9G"
      },
      "source": [
        "# PAY ATTENTION!\n",
        "If you want to just test an already provided model, you should skip the training part and go to [Test section](#scrollTo=Y5jJf7v5Ox91)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MbHjiIS7xGAC"
      },
      "source": [
        "# Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxEATeZ0PsA3"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194,
          "referenced_widgets": [
            "ab0c2c818a32487bbca4805317ec69ca",
            "2667d6f54c3e46428d7245ea05e00d78",
            "c430fb07d8994f55ad919e7da22768fc",
            "ed2fdad51f7b489c9b5e0ed6bec63ba6",
            "d34b361c302e410391205dcd47823d7d",
            "2b095bf2166845c3b2de443d4db7a242",
            "929bb4a884234b178330e3f52c8c95e6",
            "0d7ea6b6b93c4c0a93a7ac3e3632278f",
            "ae6569439ebf4bac982c32683fc1a8eb",
            "67498f5c8d064aca8addf7040d9753fa",
            "62654fdb5ecc47f082810e8be35ed1ce"
          ]
        },
        "id": "rmFpttOdPsA3",
        "outputId": "f0a21996-57e2-4bb4-b15b-1a8f125dbf3b"
      },
      "outputs": [],
      "source": [
        "from CosPlace import model\n",
        "from model import network\n",
        "\n",
        "model = network.GeoLocalizationNet(args.backbone, args.fc_output_dim)\n",
        "\n",
        "logging.info(f\"There are {torch.cuda.device_count()} GPUs and {multiprocessing.cpu_count()} CPUs.\")\n",
        "\n",
        "if args.resume_model is not None:\n",
        "    logging.debug(f\"Loading model from {args.resume_model}\")\n",
        "    model_state_dict = torch.load(args.resume_model)\n",
        "    model.load_state_dict(model_state_dict)\n",
        "\n",
        "model = model.to(args.device).train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYVmm3_wPsA3"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdqXRnxIPsA3"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "model_optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LIlc-xSPsA4"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ArcFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEoGHYMVPsA4",
        "outputId": "a985130d-741e-48a9-8585-7b1d73770c54"
      },
      "outputs": [],
      "source": [
        "from CosPlace import datasets\n",
        "from datasets.train_dataset import TrainDataset\n",
        "from datasets.test_dataset import TestDataset\n",
        "from Team.loss.arcface import ArcFace\n",
        "from Team.loss.cosface import CosFace\n",
        "\n",
        "groups = [TrainDataset(args, args.train_set_folder, M=args.M, alpha=args.alpha, N=args.N, L=args.L,\n",
        "                       current_group=n, min_images_per_class=args.min_images_per_class) for n in range(args.groups_num)]\n",
        "\n",
        "# apply arcface loss to each group\n",
        "# Each group has its own classifier, which depends on the number of classes in the group\n",
        "classifiers = [ArcFace(args.fc_output_dim, len(group)) for group in groups]\n",
        "classifiers_optimizers = [torch.optim.Adam(classifier.parameters(), lr=args.classifiers_lr) for classifier in classifiers]\n",
        "\n",
        "logging.info(f\"Using {len(groups)} groups\")\n",
        "logging.info(f\"The {len(groups)} groups have respectively the following number of classes {[len(g) for g in groups]}\")\n",
        "logging.info(f\"The {len(groups)} groups have respectively the following number of images {[g.get_images_num() for g in groups]}\")\n",
        "\n",
        "val_ds = TestDataset(args.val_set_folder, positive_dist_threshold=args.positive_dist_threshold)\n",
        "logging.info(f\"Validation set: {val_ds}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### SphereFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from CosPlace import datasets\n",
        "from datasets.train_dataset import TrainDataset\n",
        "from datasets.test_dataset import TestDataset\n",
        "from Team.loss.sphereface import SphereFace\n",
        "\n",
        "groups = [TrainDataset(args, args.train_set_folder, M=args.M, alpha=args.alpha, N=args.N, L=args.L,\n",
        "                       current_group=n, min_images_per_class=args.min_images_per_class) for n in range(args.groups_num)]\n",
        "\n",
        "# apply sphereface loss to each group\n",
        "# Each group has its own classifier, which depends on the number of classes in the group\n",
        "classifiers = [SphereFace(args.fc_output_dim, len(group)) for group in groups]\n",
        "classifiers_optimizers = [torch.optim.Adam(classifier.parameters(), lr=args.classifiers_lr) for classifier in classifiers]\n",
        "\n",
        "logging.info(f\"Using {len(groups)} groups\")\n",
        "logging.info(f\"The {len(groups)} groups have respectively the following number of classes {[len(g) for g in groups]}\")\n",
        "logging.info(f\"The {len(groups)} groups have respectively the following number of images {[g.get_images_num() for g in groups]}\")\n",
        "\n",
        "val_ds = TestDataset(args.val_set_folder, positive_dist_threshold=args.positive_dist_threshold)\n",
        "logging.info(f\"Validation set: {val_ds}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CosFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from CosPlace import datasets\n",
        "from datasets.train_dataset import TrainDataset\n",
        "from datasets.test_dataset import TestDataset\n",
        "from Team.loss.cosface import CosFace\n",
        "\n",
        "groups = [TrainDataset(args, args.train_set_folder, M=args.M, alpha=args.alpha, N=args.N, L=args.L,\n",
        "                       current_group=n, min_images_per_class=args.min_images_per_class) for n in range(args.groups_num)]\n",
        "\n",
        "# apply cosface loss to each group\n",
        "# Each group has its own classifier, which depends on the number of classes in the group\n",
        "classifiers = [CosFace(args.fc_output_dim, len(group)) for group in groups]\n",
        "classifiers_optimizers = [torch.optim.Adam(classifier.parameters(), lr=args.classifiers_lr) for classifier in classifiers]\n",
        "\n",
        "logging.info(f\"Using {len(groups)} groups\")\n",
        "logging.info(f\"The {len(groups)} groups have respectively the following number of classes {[len(g) for g in groups]}\")\n",
        "logging.info(f\"The {len(groups)} groups have respectively the following number of images {[g.get_images_num() for g in groups]}\")\n",
        "\n",
        "val_ds = TestDataset(args.val_set_folder, positive_dist_threshold=args.positive_dist_threshold)\n",
        "logging.info(f\"Validation set: {val_ds}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNuFuBpNPsA4"
      },
      "source": [
        "## Resume train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxJEyKRzPsA4"
      },
      "outputs": [],
      "source": [
        "from CosPlace import util\n",
        "\n",
        "if args.resume_train:\n",
        "    model, model_optimizer, classifiers, classifiers_optimizers, best_val_recall1, start_epoch_num = \\\n",
        "        util.resume_train(args, output_folder, model, model_optimizer, classifiers, classifiers_optimizers)\n",
        "    model = model.to(args.device)\n",
        "    epoch_num = start_epoch_num - 1\n",
        "    logging.info(f\"Resuming from epoch {start_epoch_num} with best R@1 {best_val_recall1:.1f} from checkpoint {args.resume_train}\")\n",
        "else:\n",
        "    best_val_recall1 = start_epoch_num = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJnmjudfPsA4"
      },
      "source": [
        "## Train and Evaluation Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRWSj33fPsA4",
        "outputId": "7df6e794-46e4-4f77-a039-ac21f74cd4fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:faiss.loader:Loading faiss with AVX2 support.\n",
            "INFO:faiss.loader:Successfully loaded faiss with AVX2 support.\n",
            "INFO:root:Start training ...\n",
            "INFO:root:There are 5965 classes for the first group, each epoch has 10000 iterations with batch_size 32, therefore the model sees each class (on average) 53.6 times per epoch\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100%|███████████████████████████████████████████████████████| 10000/10000 [1:14:13<00:00,  2.25it/s]\n",
            "DEBUG:root:Epoch 00 in 1:14:14, loss = 7.9503\n",
            "DEBUG:root:Extracting database descriptors for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 501/501 [01:05<00:00,  7.64it/s]\n",
            "DEBUG:root:Extracting queries descriptors for evaluation/testing using batch size 1\n",
            "100%|███████████████████████████████████████████████████████████| 7993/7993 [01:49<00:00, 72.98it/s]\n",
            "DEBUG:root:Calculating recalls\n",
            "INFO:root:Epoch 00 in 1:17:10, < val - #q: 7993; #db: 8015 >: R@1: 78.7, R@5: 88.0\n",
            "100%|███████████████████████████████████████████████████████| 10000/10000 [1:14:16<00:00,  2.24it/s]\n",
            "DEBUG:root:Epoch 01 in 1:14:17, loss = 3.3677\n",
            "DEBUG:root:Extracting database descriptors for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 501/501 [01:04<00:00,  7.73it/s]\n",
            "DEBUG:root:Extracting queries descriptors for evaluation/testing using batch size 1\n",
            "100%|███████████████████████████████████████████████████████████| 7993/7993 [01:51<00:00, 71.48it/s]\n",
            "DEBUG:root:Calculating recalls\n",
            "INFO:root:Epoch 01 in 1:17:15, < val - #q: 7993; #db: 8015 >: R@1: 81.8, R@5: 89.9\n",
            "100%|███████████████████████████████████████████████████████| 10000/10000 [1:14:11<00:00,  2.25it/s]\n",
            "DEBUG:root:Epoch 02 in 1:14:12, loss = 2.4285\n",
            "DEBUG:root:Extracting database descriptors for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 501/501 [01:03<00:00,  7.89it/s]\n",
            "DEBUG:root:Extracting queries descriptors for evaluation/testing using batch size 1\n",
            "100%|███████████████████████████████████████████████████████████| 7993/7993 [01:49<00:00, 73.33it/s]\n",
            "DEBUG:root:Calculating recalls\n",
            "INFO:root:Epoch 02 in 1:17:06, < val - #q: 7993; #db: 8015 >: R@1: 83.2, R@5: 90.6\n",
            "INFO:root:Trained for 03 epochs, in total in 3:53:58\n"
          ]
        }
      ],
      "source": [
        "from CosPlace import augmentations, test\n",
        "\n",
        "logging.info(\"Start training ...\")\n",
        "logging.info(f\"There are {len(groups[0])} classes for the first group, \" +\n",
        "             f\"each epoch has {args.iterations_per_epoch} iterations \" +\n",
        "             f\"with batch_size {args.batch_size}, therefore the model sees each class (on average) \" +\n",
        "             f\"{args.iterations_per_epoch * args.batch_size / len(groups[0]):.1f} times per epoch\")\n",
        "\n",
        "\n",
        "if args.augmentation_device == \"cuda\":\n",
        "    gpu_augmentation = T.Compose([\n",
        "            augmentations.DeviceAgnosticColorJitter(brightness=args.brightness,\n",
        "                                                    contrast=args.contrast,\n",
        "                                                    saturation=args.saturation,\n",
        "                                                    hue=args.hue),\n",
        "            augmentations.DeviceAgnosticRandomResizedCrop([512, 512],\n",
        "                                                          scale=[1-args.random_resized_crop, 1]),\n",
        "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "if args.use_amp16:\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "for epoch_num in range(start_epoch_num, args.epochs_num):\n",
        "    \n",
        "    #### Train\n",
        "    epoch_start_time = datetime.now()\n",
        "    # Select classifier and dataloader according to epoch\n",
        "    current_group_num = epoch_num % args.groups_num\n",
        "    classifiers[current_group_num] = classifiers[current_group_num].to(args.device)\n",
        "    util.move_to_device(classifiers_optimizers[current_group_num], args.device)\n",
        "    \n",
        "    dataloader = commons.InfiniteDataLoader(groups[current_group_num], num_workers=args.num_workers,\n",
        "                                            batch_size=args.batch_size, shuffle=True,\n",
        "                                            pin_memory=(args.device == \"cuda\"), drop_last=True)\n",
        "    \n",
        "    dataloader_iterator = iter(dataloader)\n",
        "    model = model.train()\n",
        "    \n",
        "    epoch_losses = np.zeros((0, 1), dtype=np.float32)\n",
        "    for iteration in tqdm(range(args.iterations_per_epoch), ncols=100):\n",
        "        images, targets, _ = next(dataloader_iterator)\n",
        "        images, targets = images.to(args.device), targets.to(args.device)\n",
        "        \n",
        "        if args.augmentation_device == \"cuda\":\n",
        "            images = gpu_augmentation(images)\n",
        "        \n",
        "        model_optimizer.zero_grad()\n",
        "        classifiers_optimizers[current_group_num].zero_grad()\n",
        "        \n",
        "        if not args.use_amp16:\n",
        "            descriptors = model(images)\n",
        "            output = classifiers[current_group_num](descriptors, targets)\n",
        "            loss = criterion(output, targets)\n",
        "            loss.backward()\n",
        "            epoch_losses = np.append(epoch_losses, loss.item())\n",
        "            del loss, output, images\n",
        "            model_optimizer.step()\n",
        "            classifiers_optimizers[current_group_num].step()\n",
        "        else:  # Use AMP 16\n",
        "            with torch.cuda.amp.autocast():\n",
        "                descriptors = model(images)\n",
        "                output = classifiers[current_group_num](descriptors, targets)\n",
        "                loss = criterion(output, targets)\n",
        "            scaler.scale(loss).backward()\n",
        "            epoch_losses = np.append(epoch_losses, loss.item())\n",
        "            del loss, output, images\n",
        "            scaler.step(model_optimizer)\n",
        "            scaler.step(classifiers_optimizers[current_group_num])\n",
        "            scaler.update()\n",
        "    \n",
        "    classifiers[current_group_num] = classifiers[current_group_num].cpu()\n",
        "    util.move_to_device(classifiers_optimizers[current_group_num], \"cpu\")\n",
        "    \n",
        "    logging.debug(f\"Epoch {epoch_num:02d} in {str(datetime.now() - epoch_start_time)[:-7]}, \"\n",
        "                  f\"loss = {epoch_losses.mean():.4f}\")\n",
        "    \n",
        "    #### Evaluation\n",
        "    recalls, recalls_str = test.test(args, val_ds, model)\n",
        "    logging.info(f\"Epoch {epoch_num:02d} in {str(datetime.now() - epoch_start_time)[:-7]}, {val_ds}: {recalls_str[:20]}\")\n",
        "    is_best = recalls[0] > best_val_recall1\n",
        "    best_val_recall1 = max(recalls[0], best_val_recall1)\n",
        "    # Save checkpoint, which contains all training parameters\n",
        "    util.save_checkpoint({\n",
        "        \"epoch_num\": epoch_num + 1,\n",
        "        \"model_state_dict\": model.state_dict(),\n",
        "        \"optimizer_state_dict\": model_optimizer.state_dict(),\n",
        "        \"classifiers_state_dict\": [c.state_dict() for c in classifiers],\n",
        "        \"optimizers_state_dict\": [c.state_dict() for c in classifiers_optimizers],\n",
        "        \"best_val_recall1\": best_val_recall1\n",
        "    }, is_best, output_folder)\n",
        "\n",
        "\n",
        "logging.info(f\"Trained for {epoch_num+1:02d} epochs, in total in {str(datetime.now() - start_time)[:-7]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5jJf7v5Ox91"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ItObSaBl6ox"
      },
      "source": [
        "## Import model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzJGjw9xxGAE",
        "outputId": "368c1fd4-a805-4420-a9f2-26f8481e48ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "DEBUG:root:Train only layer3 and layer4 of the resnet18, freeze the previous ones\n",
            "INFO:root:There are 1 GPUs and 2 CPUs.\n",
            "INFO:root:Loading model from /content/logs/default/2022-12-13_12-16-57/best_model.pth\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from CosPlace import model, test, datasets\n",
        "from model import network\n",
        "from datasets.test_dataset import TestDataset\n",
        "\n",
        "#### Model\n",
        "model = network.GeoLocalizationNet(args.backbone, args.fc_output_dim)\n",
        "\n",
        "logging.info(f\"There are {torch.cuda.device_count()} GPUs and {multiprocessing.cpu_count()} CPUs.\")\n",
        "\n",
        "# set the path to the model you want to resume\n",
        "# the following line will take the model trained here\n",
        "# resume_model = f\"/content/logs/default/{start_time.strftime('%Y-%m-%d_%H-%M-%S')}/best_model.pth\"\n",
        "if args.resume_model is not None:\n",
        "  if os.path.exists(args.resume_model):\n",
        "    resume_model = args.resume_model\n",
        "if os.path.exists(resume_model):\n",
        "  logging.info(f\"Loading model from {resume_model}\")\n",
        "  model_state_dict = torch.load(resume_model)\n",
        "  model.load_state_dict(model_state_dict)\n",
        "else:\n",
        "    logging.info(\"WARNING: You didn't provide a path to resume the model (--resume_model parameter). \" +\n",
        "                 \"Evaluation will be computed using randomly initialized weights.\")\n",
        "\n",
        "model = model.to(args.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVEznMFwxGAE"
      },
      "source": [
        "## Test on SF-XS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuyMy5pCweIZ"
      },
      "source": [
        "Test the model on the sf-xs (test) dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XZjk3Z2O1m6",
        "outputId": "3882973c-abb1-44be-9eb4-532925ca0a5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:root:Extracting database descriptors for evaluation/testing\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100%|███████████████████████████████████████████████████████████| 1700/1700 [03:41<00:00,  7.69it/s]\n",
            "DEBUG:root:Extracting queries descriptors for evaluation/testing using batch size 1\n",
            "100%|███████████████████████████████████████████████████████████| 1000/1000 [00:16<00:00, 61.62it/s]\n",
            "DEBUG:root:Calculating recalls\n",
            "INFO:root:< test - #q: 1000; #db: 27191 >: R@1: 52.2, R@5: 66.3, R@10: 71.8, R@20: 76.3\n"
          ]
        }
      ],
      "source": [
        "# dataset_folder is the same of the training\n",
        "test_set_folder = os.path.join(DATASET_FOLDER, \"test\")\n",
        "if not os.path.exists(test_set_folder):\n",
        "    raise FileNotFoundError(f\"Test set folder {test_set_folder} not found\")\n",
        "\n",
        "test_ds = TestDataset(test_set_folder, queries_folder=\"queries_v1\",\n",
        "                      positive_dist_threshold=args.positive_dist_threshold)\n",
        "\n",
        "recalls, recalls_str = test.test(args, test_ds, model)\n",
        "logging.info(f\"{test_ds}: {recalls_str}\")\n",
        "\n",
        "# recalls for csv file\n",
        "sf_xs_r15 = f\"{recalls[0]}/{recalls[1]}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCUwEkPHSpD7"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q28MxTcweIZ"
      },
      "source": [
        "## Test on Tokyo-XS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdmjVczqweIZ"
      },
      "source": [
        "Test the model on the tokyo-xs dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJgmqoCgPxwu",
        "outputId": "09b1a9b6-53d2-4a2f-ac9e-f4a8946ffb95"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:root:Extracting database descriptors for evaluation/testing\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100%|█████████████████████████████████████████████████████████████| 799/799 [02:09<00:00,  6.18it/s]\n",
            "DEBUG:root:Extracting queries descriptors for evaluation/testing using batch size 1\n",
            "100%|█████████████████████████████████████████████████████████████| 315/315 [00:05<00:00, 55.87it/s]\n",
            "DEBUG:root:Calculating recalls\n",
            "INFO:root:< test - #q: 315; #db: 12771 >: R@1: 69.5, R@5: 84.8, R@10: 89.2, R@20: 93.0\n"
          ]
        }
      ],
      "source": [
        "tokyo_xs_folder = \"/content/tokyo_xs\"\n",
        "test_set_folder = os.path.join(tokyo_xs_folder, \"test\")\n",
        "if not os.path.exists(test_set_folder):\n",
        "    raise FileNotFoundError(f\"Test set folder {test_set_folder} not found\")\n",
        "\n",
        "test_ds = TestDataset(test_set_folder,\n",
        "                      positive_dist_threshold=args.positive_dist_threshold)\n",
        "\n",
        "recalls, recalls_str = test.test(args, test_ds, model)\n",
        "logging.info(f\"{test_ds}: {recalls_str}\")\n",
        "\n",
        "# recalls for csv file\n",
        "tokyo_xs_r15 = f\"{recalls[0]:.1f}/{recalls[1]:.1f}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0tHKhzeweIZ"
      },
      "source": [
        "## Test on Tokyo-Night"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTc8pkpuweIa"
      },
      "source": [
        "Test the model on the tokyo-night dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9Vzh7YNQrQa",
        "outputId": "4dd7ce9c-ea4d-4ab4-b3a3-bb12c1c3846c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:root:Extracting database descriptors for evaluation/testing\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100%|█████████████████████████████████████████████████████████████| 799/799 [02:06<00:00,  6.29it/s]\n",
            "DEBUG:root:Extracting queries descriptors for evaluation/testing using batch size 1\n",
            "100%|█████████████████████████████████████████████████████████████| 105/105 [00:02<00:00, 41.85it/s]\n",
            "DEBUG:root:Calculating recalls\n",
            "INFO:root:< test - #q: 105; #db: 12771 >: R@1: 50.5, R@5: 72.4, R@10: 79.0, R@20: 85.7\n"
          ]
        }
      ],
      "source": [
        "tokyo_night_folder = \"/content/tokyo-night/\"\n",
        "test_set_folder = os.path.join(tokyo_night_folder, \"test\")\n",
        "if not os.path.exists(test_set_folder):\n",
        "    raise FileNotFoundError(f\"Test set folder {test_set_folder} not found\")\n",
        "\n",
        "test_ds = TestDataset(test_set_folder,\n",
        "                      positive_dist_threshold=args.positive_dist_threshold)\n",
        "\n",
        "recalls, recalls_str = test.test(args, test_ds, model)\n",
        "logging.info(f\"{test_ds}: {recalls_str}\")\n",
        "\n",
        "# recalls for csv file\n",
        "tokyo_night_r15 = f\"{recalls[0]:.1f}/{recalls[1]:.1f}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vPCrdJInVZ8"
      },
      "source": [
        "# Save results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cN8-2dhweIa"
      },
      "source": [
        "## Create CSV with recalls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_zxkamqncCt"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "header = [\"sf-xs (test)\", \"Tokyo-xs\", \"Tokyo-night\"]\n",
        "data = [sf_xs_r15, tokyo_xs_r15, tokyo_night_r15]\n",
        "\n",
        "logging.info(f\"Table results: {zip(header, data)}\")\n",
        "\n",
        "with open(f\"/content/{SAVEDIR}_{start_time.strftime('%Y-%m-%d_%H-%M-%S')}.csv\", \"w\") as f:\n",
        "  writer = csv.writer(f)\n",
        "\n",
        "  writer.writerow(header)\n",
        "  writer.writerow(data)\n",
        "logging.info(f\"save table results to /content/{SAVEDIR}{start_time.strftime('%Y-%m-%d_%H-%M-%S')}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQXOjFvsweIa"
      },
      "source": [
        "## Save on Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ArcFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "modelLocal = \"arcface_model.pth\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### SphereFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "modelLocal = \"sphereface_model.pth\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### CosFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "modelLocal = \"cosface_model.pth\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPIfX1yp_dtj"
      },
      "source": [
        "Save all data generated by this notebook in a specific folder in **PERSONAL** gdrive. Remember to copy inside shared_data of project drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnPzKaCQ-xRD",
        "outputId": "f42daa42-d618-4ee1-db5e-3306356c2393"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "updating: content/logs/ (stored 0%)\n",
            "updating: content/logs/content/ (stored 0%)\n",
            "updating: content/logs/content/saved_models/ (stored 0%)\n",
            "updating: content/logs/content/saved_models/2022-12-11_17-17-27/ (stored 0%)\n",
            "updating: content/logs/content/saved_models/2022-12-11_17-17-27/debug.log (deflated 66%)\n",
            "updating: content/logs/content/saved_models/2022-12-11_17-17-27/info.log (deflated 58%)\n",
            "updating: content/logs/content/saved_models/2022-12-11_17-17-27/best_model.pth (deflated 7%)\n",
            "updating: content/logs/content/saved_models/2022-12-11_17-17-27/last_checkpoint.pth (deflated 8%)\n",
            "updating: content/logs/default/ (stored 0%)\n",
            "updating: content/logs/default/2022-12-13_12-16-57/ (stored 0%)\n",
            "updating: content/logs/default/2022-12-13_12-16-57/debug.log (deflated 67%)\n",
            "updating: content/logs/default/2022-12-13_12-16-57/info.log (deflated 58%)\n",
            "updating: content/logs/default/2022-12-13_12-16-57/best_model.pth (deflated 7%)\n",
            "updating: content/logs/default/2022-12-13_12-16-57/last_checkpoint.pth (deflated 8%)\n",
            "updating: content/cache/ (stored 0%)\n",
            "updating: content/cache/small_M10_N5_mipc10.torch (deflated 74%)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "if not os.path.exists(\"/content/drive/MyDrive/step_3\"):\n",
        "  !mkdir /content/drive/MyDrive/step_3\n",
        "  !cp f\"/content/logs/{SAVEDIR}/{start_time.strftime('%Y-%m-%d_%H-%M-%S')}/best_model.pth\" f\"/content/drive/MyDrive/step_3/{modelLocal}\"\n",
        "  \n",
        "\n",
        "#!cp \"/content/{SAVEDIR}{start_time.strftime('%Y-%m-%d_%H-%M-%S')}.csv\" /content/drive/MyDrive/step_2/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "qf3z5SqWZ91b"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d7ea6b6b93c4c0a93a7ac3e3632278f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2667d6f54c3e46428d7245ea05e00d78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b095bf2166845c3b2de443d4db7a242",
            "placeholder": "​",
            "style": "IPY_MODEL_929bb4a884234b178330e3f52c8c95e6",
            "value": "100%"
          }
        },
        "2b095bf2166845c3b2de443d4db7a242": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62654fdb5ecc47f082810e8be35ed1ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67498f5c8d064aca8addf7040d9753fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "929bb4a884234b178330e3f52c8c95e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab0c2c818a32487bbca4805317ec69ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2667d6f54c3e46428d7245ea05e00d78",
              "IPY_MODEL_c430fb07d8994f55ad919e7da22768fc",
              "IPY_MODEL_ed2fdad51f7b489c9b5e0ed6bec63ba6"
            ],
            "layout": "IPY_MODEL_d34b361c302e410391205dcd47823d7d"
          }
        },
        "ae6569439ebf4bac982c32683fc1a8eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c430fb07d8994f55ad919e7da22768fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d7ea6b6b93c4c0a93a7ac3e3632278f",
            "max": 46830571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae6569439ebf4bac982c32683fc1a8eb",
            "value": 46830571
          }
        },
        "d34b361c302e410391205dcd47823d7d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed2fdad51f7b489c9b5e0ed6bec63ba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67498f5c8d064aca8addf7040d9753fa",
            "placeholder": "​",
            "style": "IPY_MODEL_62654fdb5ecc47f082810e8be35ed1ce",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 129MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
