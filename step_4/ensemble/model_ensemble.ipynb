{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gab-palmeri/aml-geolocalization/blob/sam/step_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "n18u6OFZxF_z"
      },
      "source": [
        "The purpose of this notebook is to test the ensemble of two or more networks where the logits are the mean of the logits of each network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf3z5SqWZ91b"
      },
      "source": [
        "# pip install requirements\n",
        "\n",
        "Remember to click on \"Restart Runtime\" before go on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YbtEmI1AiTkF",
        "outputId": "5d3b09bb-c84a-400a-e68f-e3a4ca7ab472"
      },
      "outputs": [],
      "source": [
        "# CosPlace requirements\n",
        "!pip3 install \"faiss_cpu>=1.7.1\"\n",
        "!pip3 install \"numpy>=1.21.2\"\n",
        "!pip3 install \"Pillow>=9.0.1\"\n",
        "!pip3 install \"scikit_learn>=1.0.2\"\n",
        "!pip3 install \"torch>=1.8.2\"\n",
        "!pip3 install \"torchvision>=0.9.2\"\n",
        "!pip3 install \"tqdm>=4.62.3\"\n",
        "!pip3 install \"utm>=0.7.0\"\n",
        "\n",
        "import torch\n",
        "#use GPU if available \n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #'cpu' # 'cuda' or 'cpu'\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czjvnq3FjBmh"
      },
      "source": [
        "# Download Datasets and previous data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_hY8bYPGyqLF"
      },
      "source": [
        "Downloading with gdown doesn't work properly because after N downloads it stops working. So we prefer to use drive / mount with a shared folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "use_mount = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGOhXMNqjMed",
        "outputId": "4c11717c-1818-4386-d3bd-48bb13bc2a47"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gdown\n",
        "from google.colab import drive\n",
        "\n",
        "def download(id, output=None, quiet=True):\n",
        "  gdown.download(\n",
        "    f\"https://drive.google.com/uc?export=download&confirm=pbef&id={id}\",\n",
        "    output=output,\n",
        "    quiet=quiet\n",
        "  )\n",
        "\n",
        "\n",
        "if use_mount:\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "# TOKYO-XS DATASET\n",
        "if not os.path.isdir(\"/content/tokyo_xs\"):\n",
        "  if use_mount:\n",
        "    !jar xvf \"/content/drive/MyDrive/Project 6 - Dataset/tokyo-xs.zip\"\n",
        "  else:\n",
        "    id = \"1fBCnap5BRh36474cVkjvjlC-yUTEb1n3\"\n",
        "    download(id, quiet=False)                           # download from our gdrive\n",
        "    !jar xvf \"/content/tokyo-xs.zip\"                    # unzip\n",
        "    !rm -r \"/content/tokyo-xs.zip\"                      # remove .zip file\n",
        "\n",
        "if not os.path.isdir(\"/content/tokyo_xs\"):\n",
        "  raise FileNotFoundError(f\"Can't download tokyo xs\")\n",
        "\n",
        "#TOKYO NIGHT DATASET\n",
        "if not os.path.isdir(\"/content/tokyo-night\"):\n",
        "  if use_mount:\n",
        "    !jar xvf \"/content/drive/MyDrive/Project 6 - Dataset/tokyo-night.zip\"\n",
        "  else:\n",
        "    id = \"1EZJY2r5565-iVk2oEbTns0xc4F_em4Y4\"\n",
        "    download(id, quiet=False)                           # download from our gdrive\n",
        "    !jar xvf \"/content/tokyo-night.zip\"                    # unzip\n",
        "    !rm -r \"/content/tokyo-night.zip\"\n",
        "\n",
        "if not os.path.isdir(\"/content/tokyo-night\"):\n",
        "  raise FileNotFoundError(f\"Can't download tokyo night\")\n",
        "\n",
        "# SAN FRANCISCO - XS DATASET\n",
        "if not os.path.isdir(\"/content/small\"):\n",
        "  if use_mount:\n",
        "    !jar xvf \"/content/drive/MyDrive/Project 6 - Dataset/sf-xs.zip\"\n",
        "  else:\n",
        "    id = \"1brIxBJmOgvuzFbI57f5LxnMxjccUu993\"\n",
        "    download(id, quiet=False)                           # download\n",
        "    !jar xvf \"/content/sf-xs.zip\"                       # unzip\n",
        "    !rm -r \"/content/sf-xs.zip\"                         # remove .zip file\n",
        "\n",
        "if not os.path.isdir(\"/content/small\"):\n",
        "  raise FileNotFoundError(f\"Can't download sfxs\")\n",
        "\n",
        "# MODEL TO ENSEMBLE\n",
        "if not os.path.isdir(\"/content/content\"):\n",
        "  if use_mount:\n",
        "    !jar xvf \"/content/myDrive/MyDrive/shared/models_to_ensemble.zip\"\n",
        "  else:\n",
        "    id = \"1hDBK9y4bzvT90cnRdJ5OzkgkkmQAwtmE\"\n",
        "    download(id, quiet=False)                           # download\n",
        "    !jar xvf \"/content/models_to_ensemble.zip\"          # unzip\n",
        "    !rm -r \"/content/models_to_ensemble.zip\"            # remove .zip file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g6SkCgyhl-g"
      },
      "source": [
        "# Download Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFrIIf6E0UQM"
      },
      "source": [
        "Clone of original repo of CosPlace and our code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63SgJ_Y0hwrC",
        "outputId": "fed6492f-479d-403e-bd7f-433482628191"
      },
      "outputs": [],
      "source": [
        "# download code of CosPlace\n",
        "!git clone \"https://github.com/gmberton/CosPlace\" \n",
        "#!rm -r \"/content/CosPlace\"\n",
        "\n",
        "# download our code\n",
        "!git clone --single-branch --branch \"develop\" \"https://github.com/gab-palmeri/aml-geolocalization.git\"\n",
        "!mv \"/content/aml-geolocalization/\" \"/content/Team\"\n",
        "#!rm -r \"/content/aml-geolocalization\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiwWzjzSio-h"
      },
      "source": [
        "\n",
        "\n",
        "# Import Code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAd54tr_cNtO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import logging\n",
        "import multiprocessing\n",
        "import numpy as np\n",
        "import torchvision.transforms as T\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "sys.path.append(\"/content/CosPlace/\")\n",
        "sys.path.append(\"/content/Team/\")\n",
        "import CosPlace\n",
        "from CosPlace import *\n",
        "\n",
        "torch.backends.cudnn.benchmark = True  # Provides a speedup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MsFj6mmaYJs"
      },
      "source": [
        "This class let us to access to dictionary keys like `dict.key` instead of `dict[\"key\"]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKoLeQ_1xGAA"
      },
      "outputs": [],
      "source": [
        "class dotdict(dict):\n",
        "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
        "    __getattr__ = dict.get\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb9otl0RvDI3"
      },
      "source": [
        "Drive related functions to save and load training checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcM7DpMovDI3",
        "outputId": "8d521311-3cd9-4ac0-fae9-07c4c60336d5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def drive_save_checkpoint(output_folder, time=None, drive_folder=\"/content/drive/MyDrive/project6/\"):\n",
        "    if time is None:\n",
        "        raise ValueError(\"time must be specified\")\n",
        "    if not os.path.exists(drive_folder):\n",
        "        !mkdir \"{drive_folder}\"\n",
        "    !zip -r \"{drive_folder}{time}.zip\" \"/content/{output_folder}\"\n",
        "\n",
        "def drive_load_checkpoint(drive_folder=\"/content/drive/MyDrive/project6/\", time=None):\n",
        "    if time is None:\n",
        "        raise ValueError(\"time must be specified\")\n",
        "    !jar xvf \"{input_folder}{time}.zip\"\n",
        "\n",
        "def drive_tester(output_folder, drive_folder=\"/content/drive/MyDrive/project6/\"):\n",
        "    if not os.path.exists(drive_folder):\n",
        "        !mkdir \"{drive_folder}\"\n",
        "    !touch \"{drive_folder}test\"\n",
        "\n",
        "    if os.path.exists(\"{drive_folder}test\"):\n",
        "        logging.info(\"Drive saving works\")\n",
        "    else:\n",
        "        logging.info(\"WARNING: Drive saving does not work\")\n",
        "\n",
        "# use this function when content on drive are not updated\n",
        "def drive_refresh():\n",
        "  drive.flush_and_unmount()\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpbRF7uZxGAB"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_UnO_6a0amb"
      },
      "source": [
        "Original code provides two main executable files: `train.py` and `eval.py`. We want to reproduce the same behaviour of these two files so these are the parameters passed via terminal. They will be put in a dict called `args` to simply reuse code inside ex files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tOcIQ1Fwni7"
      },
      "source": [
        "## Setup parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sI0BfY2_xGAB"
      },
      "outputs": [],
      "source": [
        "# CosPlace Groups parameters\n",
        "COS_M = 10\n",
        "ALPHA = 30\n",
        "COS_N = 5\n",
        "COS_L = 2\n",
        "GROUPS_NUM = 1\n",
        "MIN_IMAGES_PER_CLASS = 10\n",
        "# Model parameters\n",
        "BACKBONE = \"resnet18\"   \n",
        "# [\"resnet18\", \"efficientnet_b2\", \"efficientnet_v2_s\", \"mobilenet_v3_small\", \"mobilenet_v3_large\",\n",
        "# [\"convnext_tiny\", \"swin_tiny\" ]\n",
        "FC_OUTPUT_DIM = 512     # Output dimension of final fully connected layer\n",
        "PRETRAIN = \"imagenet\"   # [\"imagenet\", \"places\", \"gldv2\"]\n",
        "# Training parameters\n",
        "AUGMENTATION_DEVICE = \"cuda\"    # [\"cuda\", \"cpu\"]\n",
        "USE_AMP_16 = AUGMENTATION_DEVICE == \"cuda\"       # use Automatic Mixed Precision\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS_NUM = 3\n",
        "ITERATIONS_PER_EPOCH = 10_000\n",
        "LR = 0.00001                    # Learning rate  \n",
        "CLASSIFIERS_LR = 0.01\n",
        "# Data augmentation\n",
        "RESIZE_AS_DB = True\n",
        "BRIGHTNESS = 0.7\n",
        "CONTRAST = 0.7\n",
        "SATURATION = 0.7\n",
        "HUE = 0.5\n",
        "RANDOM_RESIZED_CROP = 0.5\n",
        "RANDOM_H_FLIP = False\n",
        "MAJORITY_WEIGHT = 0.01\n",
        "# Validation / test parameters\n",
        "INFER_BATCH_SIZE = 16           # Batch size for inference (validating and testing)\n",
        "POSITIVE_DIST_THRESHOLD = 25    # distance in meters for a prediction to be considered a positive\n",
        "# Resume parameters\n",
        "RESUME_TRAIN = None     # path to checkpoint to resume, e.g. logs/.../last_checkpoint.pth\n",
        "RESUME_MODEL = None     # Path to model to resume training from\n",
        "# Other parameters\n",
        "DEVICE = \"cuda\"                     # [\"cuda\", \"cpu\"]\n",
        "SEED = 0\n",
        "NUM_WORKERS = 8\n",
        "DATASET_FOLDER = \"/content/small\"   # path of the folder with train/val sets\n",
        "SAVEDIR = BACKBONE + \"_\" + PRETRAIN\n",
        "TEST_METHOD = \"central_crop\"\n",
        "\n",
        "\n",
        "if not os.path.exists(DATASET_FOLDER):\n",
        "    raise FileNotFoundError(f\"Dataset folder {DATASET_FOLDER} not found\")\n",
        "\n",
        "train_set_folder = os.path.join(DATASET_FOLDER, \"train\")\n",
        "\n",
        "if not os.path.exists(train_set_folder):\n",
        "    raise FileNotFoundError(f\"Train set folder {train_set_folder} not found\")\n",
        "\n",
        "val_set_folder = os.path.join(DATASET_FOLDER, \"val\")\n",
        "\n",
        "if not os.path.exists(val_set_folder):\n",
        "    raise FileNotFoundError(f\"Validation set folder {val_set_folder} not found\")\n",
        "\n",
        "if BACKBONE != \"resnet18\" and PRETRAIN != \"imagenet\":\n",
        "    raise ValueError(\"Only resnet18 can be pretrained on other datasets than ImageNet\")\n",
        "\n",
        "# dictionary for the parameters\n",
        "args = {\n",
        "    'M': COS_M, 'alpha': ALPHA, 'N': COS_N, 'L': COS_L, 'groups_num': GROUPS_NUM,\n",
        "    'min_images_per_class': MIN_IMAGES_PER_CLASS, 'backbone': BACKBONE, \"pretrain\": PRETRAIN,\n",
        "    'fc_output_dim': FC_OUTPUT_DIM, 'use_amp16': USE_AMP_16,\n",
        "    'augmentation_device': AUGMENTATION_DEVICE, 'batch_size': BATCH_SIZE,\n",
        "    'epochs_num': EPOCHS_NUM, 'iterations_per_epoch': ITERATIONS_PER_EPOCH,\n",
        "    'lr': LR, 'classifiers_lr': CLASSIFIERS_LR, 'brightness': BRIGHTNESS, 'resize_as_db': RESIZE_AS_DB,\n",
        "    'contrast': CONTRAST, 'hue': HUE, 'saturation': SATURATION, 'hflip': RANDOM_H_FLIP, 'maj_weight': MAJORITY_WEIGHT,\n",
        "    'random_resized_crop': RANDOM_RESIZED_CROP, 'infer_batch_size': INFER_BATCH_SIZE,\n",
        "    'positive_dist_threshold': POSITIVE_DIST_THRESHOLD, 'resume_train': RESUME_TRAIN,\n",
        "    'resume_model': RESUME_MODEL, 'device': DEVICE, 'seed': SEED,\n",
        "    'num_workers': NUM_WORKERS, 'dataset_folder': DATASET_FOLDER, 'save_dir': SAVEDIR,\n",
        "    'val_set_folder': val_set_folder, 'train_set_folder': train_set_folder, 'test_method': TEST_METHOD\n",
        "}\n",
        "\n",
        "# this helps to reuse the code from the original CosPlace\n",
        "args = dotdict(args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "saveDirLocal = SAVEDIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weAbHrt3PsA3"
      },
      "source": [
        "# Setup logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF4OSAc0PsA3",
        "outputId": "9a3b8b28-b974-47e8-d29e-16ecaf7200e9"
      },
      "outputs": [],
      "source": [
        "from CosPlace import commons\n",
        "\n",
        "start_time = datetime.now()\n",
        "output_folder = f\"logs/{args.save_dir}/{start_time.strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
        "commons.make_deterministic(args.seed)\n",
        "commons.setup_logging(output_folder, console=None)\n",
        "logging.info(\" \".join(sys.argv))\n",
        "logging.info(f\"Arguments: {args}\")\n",
        "logging.info(f\"The outputs are being saved in {output_folder}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5jJf7v5Ox91"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Models to ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from Team.model.network import GeoLocalizationNet\n",
        "\n",
        "# define paths of state dicts\n",
        "paths = [\n",
        "    \"/content/content/resnet18_imagenet.pth\",\n",
        "    \"/content/content/mobilenet_v3_large_imagenet.pth\",\n",
        "    \"/content/content/efficientnet_v2_s_imagenet.pth\"\n",
        "]\n",
        "\n",
        "for path in paths:\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"Model {path} not found, you have to provide the state dicts of the models\")\n",
        "\n",
        "state_dicts = [torch.load(x) for x in paths]\n",
        "\n",
        "\n",
        "# create models\n",
        "\n",
        "models = [\n",
        "    GeoLocalizationNet(\"resnet18\", args.fc_output_dim),\n",
        "    GeoLocalizationNet(\"mobilenet_v3_large\", args.fc_output_dim),\n",
        "    GeoLocalizationNet(\"efficientnet_v2_s\", args.fc_output_dim)\n",
        "]\n",
        "\n",
        "# load state dicts\n",
        "for i, model in enumerate(models):\n",
        "    model.load_state_dict(state_dicts[i])\n",
        "    model = model.to(args.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ItObSaBl6ox"
      },
      "source": [
        "## Import model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from Team.model.ensemble import ModelEnsembler\n",
        "\n",
        "\n",
        "model = ModelEnsembler(models)\n",
        "model = model.to(args.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVEznMFwxGAE"
      },
      "source": [
        "## Test on SF-XS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuyMy5pCweIZ"
      },
      "source": [
        "Test the model on the sf-xs (test) dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XZjk3Z2O1m6",
        "outputId": "b57b3565-b272-47a6-fee5-1c72cf819b06"
      },
      "outputs": [],
      "source": [
        "from Team.datasets.test_dataset import DataAugTestDataset as TestDataset\n",
        "from Team import test\n",
        "\n",
        "# dataset_folder is the same of the training\n",
        "test_set_folder = os.path.join(DATASET_FOLDER, \"test\")\n",
        "if not os.path.exists(test_set_folder):\n",
        "    raise FileNotFoundError(f\"Test set folder {test_set_folder} not found\")\n",
        "\n",
        "test_ds = TestDataset(test_set_folder, queries_folder=\"queries_v1\",\n",
        "                      positive_dist_threshold=args.positive_dist_threshold, test_method=args.test_method, resize = args.resize_as_db)\n",
        "\n",
        "recalls, recalls_str = test.test(args, test_ds, model)\n",
        "logging.info(f\"{test_ds}: {recalls_str}\")\n",
        "\n",
        "# recalls for csv file\n",
        "sf_xs_r15 = f\"{recalls[0]:.1f}/{recalls[1]:.1f}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCUwEkPHSpD7"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q28MxTcweIZ"
      },
      "source": [
        "## Test on Tokyo-XS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdmjVczqweIZ"
      },
      "source": [
        "Test the model on the tokyo-xs dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJgmqoCgPxwu",
        "outputId": "7fefb978-b97a-48ed-d0d5-b7bf5c157df8"
      },
      "outputs": [],
      "source": [
        "tokyo_xs_folder = \"/content/tokyo_xs\"\n",
        "test_set_folder = os.path.join(tokyo_xs_folder, \"test\")\n",
        "if not os.path.exists(test_set_folder):\n",
        "    raise FileNotFoundError(f\"Test set folder {test_set_folder} not found\")\n",
        "\n",
        "test_ds = TestDataset(test_set_folder,\n",
        "                      positive_dist_threshold=args.positive_dist_threshold, test_method=args.test_method, resize = args.resize_as_db)\n",
        "\n",
        "recalls, recalls_str = test.test(args, test_ds, model)\n",
        "logging.info(f\"{test_ds}: {recalls_str}\")\n",
        "\n",
        "# recalls for csv file\n",
        "tokyo_xs_r15 = f\"{recalls[0]:.1f}/{recalls[1]:.1f}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0tHKhzeweIZ"
      },
      "source": [
        "## Test on Tokyo-Night"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTc8pkpuweIa"
      },
      "source": [
        "Test the model on the tokyo-night dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9Vzh7YNQrQa",
        "outputId": "521f7df9-34cf-4536-e6e5-1d333cd0190f"
      },
      "outputs": [],
      "source": [
        "tokyo_night_folder = \"/content/tokyo-night/\"\n",
        "test_set_folder = os.path.join(tokyo_night_folder, \"test\")\n",
        "if not os.path.exists(test_set_folder):\n",
        "    raise FileNotFoundError(f\"Test set folder {test_set_folder} not found\")\n",
        "\n",
        "test_ds = TestDataset(test_set_folder,\n",
        "                      positive_dist_threshold=args.positive_dist_threshold, test_method=args.test_method, resize = args.resize_as_db)\n",
        "\n",
        "recalls, recalls_str = test.test(args, test_ds, model)\n",
        "logging.info(f\"{test_ds}: {recalls_str}\")\n",
        "\n",
        "# recalls for csv file\n",
        "tokyo_night_r15 = f\"{recalls[0]:.1f}/{recalls[1]:.1f}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vPCrdJInVZ8"
      },
      "source": [
        "# Save results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cN8-2dhweIa"
      },
      "source": [
        "## Create CSV with recalls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_zxkamqncCt",
        "outputId": "ff92c417-5cb7-4d08-9d5c-a2785cd5dfcf"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "header = [\"sf-xs (test)\", \"Tokyo-xs\", \"Tokyo-night\"]\n",
        "data = [sf_xs_r15, tokyo_xs_r15, tokyo_night_r15]\n",
        "\n",
        "for h, d in zip(header, data):\n",
        "  logging.info(f\"{h}: {d}\")\n",
        "\n",
        "with open(f\"/content/{SAVEDIR}_{start_time.strftime('%Y-%m-%d_%H-%M-%S')}.csv\", \"w\") as f:\n",
        "  writer = csv.writer(f)\n",
        "\n",
        "  writer.writerow(header)\n",
        "  writer.writerow(data)\n",
        "logging.info(f\"save table results to /content/{SAVEDIR}{start_time.strftime('%Y-%m-%d_%H-%M-%S')}.csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "qf3z5SqWZ91b"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8 (default, Apr 13 2021, 12:59:45) \n[Clang 10.0.0 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
